<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>負荷 on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/</link><description>Recent content in 負荷 on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><atom:link href="https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/index.xml" rel="self" type="application/rss+xml"/><item><title>負荷試験</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-test/</guid><description>負荷試験 # 負荷試験の目的 # Docker SwarmからKubernetesに移行するにあたり、移行前のスペックを移行後に同等以上のスペックを発揮することを試験する必要があります。 したがって、アプリケーション自体の詳細な性能テストではなく、クラスターとして同等の性能が発揮できていることが大雑把でも確認できればよい、というのがここでのゴールとなります。
評価するためにはPrometheusやDataDog Agentなどから収集したデータをGrafanaやDataDog Dashboardで確認しつつ再現性を持った試験を実施する必要があります。
何を試験するか # 実際に試験して確認した内容を次の表にまとめました。
試験内容 目的 経路上の Proxy を最小台数にしたときに想定するrpsを処理ことができるか確かめる Connection Pool や TCP ESTABLISHED に余裕があるか確認する Runtime（nodejs）やライブラリの処理可能なrpsを計測する 同じ Runtime やライブラリを使用しているアプリケーションの CPU/MEM リソースの基準値を見積もる Pod をスケールアウトしたときの rps に対するリソースの変化を確認する Pod 数に対するリソース使用量と rps の関係を把握する 連続的にリクエストを投げることでほかサービスに影響がないか確認する 負荷試験の対象は挙動に問題ないが、同じ Gateway を使っている場合や同じマシンに乗っている他のサービスに影響がないことを確かめる 基本的に「性能限界」と「リソースの見積」のための試験になります。 これらの情報を元に、常設のreplicasの見積りや、Horizontal Pod AutoscalerのためのCPUのlimit設定、 共倒れを防ぐためのRate Limit設定を割り出していきます。
合わせてリソースの値をどうやって決めるかを確認してみてください。
試験方法 # 他のマイクロサービスと連携していないHTTPサーバーを用意する # Kubernetesの一連の動作検証も含め以下のようなサーバーを用意しておくと検証が捗ります。</description></item><item><title>モニタリング</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/monitoring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/monitoring/</guid><description>モニタリング # 言わずもがな、サーバーを持ちサービスを運用する上でモニタリングは必須です。 収集したログや Metrics は不正アクセスや障害の検知、アラートの発報などサービスの運営をする上で必ず必要な情報です。
利用しているモニタリングツール # 今回利用しているモニタリングツールは以下の 2 つがあります。
Explorer DashBoard 1 Prometheus Grafana 2 DataDog Agent DataDog 2 つ存在する理由は、費用的な面とツールの精度を確認するための理由があります。
DataDog は本番環境で使う。一部の開発環境でも検証可能な状態で利用する。 上記の DataDog を使わない環境では Prometheus と Grafana で代用する 2つのツールでモニタリングの精度を比較する（本来は最低でも 3 つあったほうが良い） どちらも同じ Metrics を収集できるため単体での Observability の差に大きく違いはありません。 ただ DataLakeとしてDataDogがすでに基盤として存在しているためメインは DataDog に各種情報が集約されています。
BFF サーバーの何を観測するか # BFF サーバーにおいて観測する主要なものは以下の表にまとめました。 どれも時系列データとして記録されるため時間変化が分かる状態になっています
BFF サーバーとして主に観測しているのは次のようなメトリクスになります。
※ 略語</description></item><item><title>負荷分散</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-balancing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-balancing/</guid><description>負荷対策 # nodeSelector # NodeはPodが配置されるVMや物理マシンですが、 配置されるPodの処理内容によって使用されるリソースが大きく変わることがあります。 具体的にはIngress Gatewayはクラスター内外のトラフィックを集中的に処理することが事前にわかっています。 また、Ingress Gatewayがなければアプリケーションにアクセスできないため、必ずリソースが枯渇しない状態にする必要があります。 そのため、Gatewayとしての役割以外を持つPodと別のNodeに配置されるようにすることで、Podが安定して稼働できるリソースの確保を実現します。
KubernetesはNodeに対してラベルを付与し、PodにnodeSelectorを付与することで指定のNodeに対してPodを配置することができます。 Nodeに付与されているlabelは以下のコマンドで確認することができます。
$ kubectl get nodes --show-labels # 簡単のため表示を省略 gateway01 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=gateway gateway02 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=gateway worker01 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=worker worker02 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=worker この場合、workerに対してPodを配置したい場合は次のように記述することができます。
1 2 3 4 5 6 7 8 9 10 11 apiVersion: apps/v1 kind: Deployment metadata: name: app namespace: demo spec: template: # 中略 spec: nodeSelector: node-role: worker Node上へのPodのスケジューリング | Kubernetes PodAntiAffinity # Podのスケジューリングはデフォルトのまま使用すると、Nodeに対する配置は明示的にコントロールされません。 つまり、あるアプリケーションを搭載したPodがNodeに偏らないようにしたいが、偏ってしまう（逆も然り）など発生します。 特にBFFサーバーはステートレスなサーバーであるため、分散配置されている方が望ましいでしょう。</description></item></channel></rss>