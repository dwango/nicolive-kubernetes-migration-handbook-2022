<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Rate Limit on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/</link><description>Recent content in Rate Limit on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><atom:link href="https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/index.xml" rel="self" type="application/rss+xml"/><item><title>Global RateLimit</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/global-ratelimit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/global-ratelimit/</guid><description>Global RateLimit # Global Rate LimitはIngress Gatewayより後方側にいるPodに対するリクエストの流量制限を実施します。 すなわち、Kubernetesクラスターまではリクエストは到達します。 envoyproxy/ratelimitはこれを実現するためのリファレンス実装で、外部サービスとして後付で導入することが可能です。
Trafficがingress gatewayに到達した後の大雑把な流れは次のとおりです。
rate_limit_serviceで指定されたマイクロサービスにたいしてgrpcで問い合わせをします。 envoyratelimitはredis（memcacheも利用可）に格納したDescriptorに対するリクエスト数の計算を実施します。 ratelimit.go#L164 fixed_cache_impl.go#L39-L128 結果をingress gatewayに対してRateLimitResponseに乗せて返却 ingress gatewayはレスポンスを受けて429を返すかどうか決定する。 Global Ratelimitの設定 # envoyproxy/ratelimitを利用するには2つの設定が必要です。
Descriptorの設置 Descriptorに対するRate Limitの定義 DescriptorはEnvoy（istio-proxy）に対して定義することが可能で、Gatewayとして機能しているistio-proxyだけでなく、Sidecarとして搭載されているistio-proxyに対しても定義することが可能です。
DescriptorはActionによって条件が定義することができ、これをリファレンス実装されたratelimitのマイクロサービスで使用することにより、特定のPATHやheaderに対してratelimitを適用することができます。
具体的な例を示しましょう。
:path単位でRate Limitをかける # 例えば、/というパスに対してRate Limitを作りたい場合、まずDescriptorをGatewayのistio-proxyに対して作る必要があります。
apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: name: ratelimit-actions spec: workloadSelector: labels: app: istio-ingressgateway configPatches: - applyTo: VIRTUAL_HOST match: context: GATEWAY routeConfiguration: vhost: name: &amp;#34;&amp;#34; route: action: ANY patch: operation: MERGE value: rate_limits: - actions: - request_headers: # HTTPの場合Request Headerの`:path`にURIが格納されている header_name: &amp;#34;:path&amp;#34; # &amp;#34;PATH&amp;#34;という名前でDescriptorを作成する descriptor_key: PATH ※ これ以降、rate_limitsより上層の定義は省略します。</description></item><item><title>Local RateLimit</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/local-ratelimit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/local-ratelimit/</guid><description>Local RateLimit # Global RateLimitとの違い
Local RateLimitとGlobal RateLimitの違いは守るスコープの違いにあります。 Global RateLimitはUpstream側のシステムを守るため、RateLimitのマイクロサービス間でリクエスト数を共有するためのストア(redisなど)を外側に持っています。 それに対し、Local RateLimitはRateLimitを提供するProxyだけがリクエスト数を保持でいればよいためインメモリーで実装することができます。
Kubernetes上におけるLocal RateLimitの設置候補
Local RateLimitを実施する候補は2つあります。
istio-proxy（Envoy）のLocal Ratelimit機能を利用する nginxをistio-proxyとAppの間に立たせ、nginxのRateLimitを利用する envoy と nginx の Rate Limit アルゴリズムの違い # envoy と nginx では Rate Limit のアルゴリズムが異なります。 ゆえに、バースト性のあるトラフィックに対する制限が異なり、どちらからの乗り換えに対しても検証なしで乗り換えすることはできません。
Proxy Server Rate Limit Algorithm nginx Leaky Bucket envoy Token Bucket envoyとnginxの設定例 # 例えばmyappというアプリケーションに対して10 rpsの Rate Limit の制限をかけ、バースト時のリクエストは50 rpsまで受け付けるようにした場合次のように記述できます。</description></item><item><title>RateLimitで負荷の上昇を防げないパターン</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/ratelimit-is-unless/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/ratelimit-is-unless/</guid><description>RateLimitで負荷の上昇を防げないパターン # RateLimit を導入したからといって必ずしも負荷状態をバーストさせない状態を作れるわけではありません。 Global RateLimit として利用可能なenvoyproxy/ratelimitや、 Envoy 本体にある Local RateLimit、nginx の持つ RateLimit の実装を注意深く見ると、RateLimit の計算に利用するのはリクエストのみです。 すなわち、レスポンスが返ったことを確認してカウントアップしたリクエスト数を下げるわけではないのです。 これはつまり、RateLimit よりも後方のサーバーがコネクションをキューイングした場合、RateLimit で指定したリクエスト数より多くのリクエストを処理することが可能になります。
発生メカニズム # 簡略化したシーケンス図でまずは状況を説明します。図中には以下が登場します。
名称 役割 User ブラウザなどのクライアント Proxy Request に対する Rate Limit を適用 Server(Frontend) BFF Server と置き換えても問題ない。図中のHeavy TaskはServer Side Renderingと解釈するとよい。 Server(Backend) Server(Frontend)が少なくとも1つ以上はクリティカルに依存するサーバー RateLimitが効いているにも関わらずServer(Frontend)のCPU使用率が上昇する流れ
何らかの理由によってServer(Backend)のレスポンスが遅くなる場合が発生 このとき、Server(Frontend)からのリクエストは設定したtimeoutまでコネクションを維持し続ける RateLimitはRequestに対してのみ有効なため、Limitが効かない間はServer(Frontend)にリクエストを送信する Server(Backend)のレスポンスタイムが正常に戻ると図中の4のResponseが発生する すると、Server(Frontend)にキューイングされたリクエストHeavy Taskが定常よりも多く実行される その結果、Server(Frontend)のCPU使用率が上昇する 問題点と対策 # 基本的にどのマイクロサービスも、連携しているマイクロサービスにSLA(Service Level Agreements)を満たせない可能性がある前提で振る舞いを決める必要があります。</description></item></channel></rss>