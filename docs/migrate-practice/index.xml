<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docker SwarmからKubernetesへの移行 on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/</link><description>Recent content in Docker SwarmからKubernetesへの移行 on ニコニコ生放送 Webフロントエンド Kubernetes移行ハンドブック 2022</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><atom:link href="https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/index.xml" rel="self" type="application/rss+xml"/><item><title>移行の実施</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/migrate-docker-swarm-to-kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/migrate-docker-swarm-to-kubernetes/</guid><description>移行の実施 # 移行前の状態（Phase 1）から移行後の状態（Phase 2）までのステップは次のような経路で実施しました。
Phase 経路 Phase 1 Apache → nginx → Container Phase 2 Apache → istio-ingressgateway → App(Docker Swarm) Phase 3 Apache → istio-ingressgateway → App(Kubernetes) Apache による経路変更はパス単位（URI 単位）で実施できるため、流量が明らかに少ないパスを管理するマイクロサービスから移行を実施しました。
移行の流れ # 移行時の細かい手順は次のようになります。
ApacheのBalancerMemberを利用してからPhase 1からPhase 2に切り替え istio-ingressgatewayとKubernetes内のネットワーク系の状態を確認 負荷試験の結果と照らし合わせて Gatewayのリソース使用量などを見る Phase 3への切り替え前に、Virtual Serviceで特定のHeaderかQuery Parameterを利用して移行後のPodに対してアクセス。 Kubernetes内への疎通も確認できた後、istio-ingressgatewayのTraffic Weightを完全に切り替える rps がそこまで高くない BFF はこの手順を繰り返すことで移行を淡々とすすめることができました。 高 rps の BFF サーバーはこの手順でやるにはリスクが高いので、トラフィックのミラーリングを実施して Gateway と Kubernetes クラスター全体の状態を確認していきます。 アクセスログで紹介したようにPodにログ出力のためのnginxが含まれるため、二重計上されないためにNodePortをistio-proxyに向けたものをミラーリングのためのポートとして提供しています。 nginxのミラーリングによって高rpsの時間変化がDataDogに蓄積され、そこから対応表を用いてリソースの逆算を実施し、移行フェーズへステップを進めることができました。</description></item><item><title>アプリケーションの移行</title><link>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/application/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dwango.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/application/</guid><description>アプリケーションの移行 # Kubernetes移行にあたりBFFサーバーで調整した内容を紹介します。
Graceful Shutdown # プロセス終了命令(SIGTERM)などのシグナルを受け取ったときに、サーバーに残っているリクエストがレスポンスを返し終わってからプロセスを終了する仕組みです。 これはKubernetesでなくても実装すべき内容で、安全に処理を終わらせるために必要です。
expressでの実装例は次のとおりです。
import * as express from &amp;#34;express&amp;#34;; const app = express(); const httpServer = app.listen(process.env.PORT || 80); // SIGNALを受け取る process.on(&amp;#34;SIGTERM&amp;#34;, () =&amp;gt; { httpServer.close(); }); process.onでSIGNALを受け取ることができるため、そこでHTTP ServerをCloseするだけになります。 他にもWebSocket Serverを起動している場合もここでclose処理を実施すると安全に終了できます。
静的リソースのアップロード # 静的リソースはAmazon S3にアップロードされたファイルをCDN(CloudFront)から配信する形式を取っています。 そのため、S3にアップロードする処理が必要で、移行前はJenkinsでこれを実行していました。
静的リソースはこれまでJenkinsのタスクによってアップロードしていましたが、KubernetesのJobとして移行しました。
具体的には、アプリケーションのCIによってリリース用のnpmパッケージが作成され、Private Registryにアップロードされたり、 ものによってはGitHubのRelease Assetsにアップロードされたりしています。
Kubernetes上のJobは
npm packageにリリースする静的リソースをダウンロードし、 静的リソースのホスティングに本当に必要なファイルだけを抽出し、 S3にアップロード という処理を実施しています。
内部の処理は環境変数で処理できるように実装されており、npmパッケージとアップロード先のS3の保存先を選ぶことができます。 また、Argo CDのSync Waveと組み合わせて、 アプリケーションのDeploymentがApplyされるより前にこのJobを実行するように順序を決めることでクリティカルパスを形成することができます。 以下は静的リソースのアップロードJobの例です。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 apiVersion: batch/v1 kind: Job metadata: name: static-resource-upload-job-v1.</description></item></channel></rss>