[{"id":0,"href":"/docs/network/architecture/","title":"移行前・移行中・移行後のネットワーク設計","section":"ネットワーク","content":"移行前・移行中・移行後のネットワーク設計 #  移行前のネットワーク構成 #  移行前のDocker Swarmのネットワーク構成図のようになっています。\nTrafficを最上位のロードバランサーで受けた後、Apacheやnginx、OpenRestyといった複数のL7ロードバランサーで受けた後に Docker Swarmのクラスターに到達し、コンテナネットワークに接続されてWebアプリケーションがレスポンスを返す様になっています。\n移行中のネットワーク構成 #  図はDocker SwarmからKubernetesに移行するにあたってネットワークのネットワーク構成になります。 基本的な移行方法としてはクラスター外のロードバランサーから新旧の環境にPATH単位でしていくことで段階的に移行することが可能です。\n今回Apacheをそのハンドルに選んだ理由は後述しています。\n移行後のネットワーク構成 #  Kubernetes上でのネットワーク構成は図のようになりました。 ApacheによるLoad Balanceは移行前のDocker Swarmと同じですが、全てのアプリケーションは一度全てIstioのIngress Gatewayを経由するようになりました。\nまた、Rate Limitなどnginxで実施していたシステムの防衛処理はKubernetesクラスター全体に対するGlobal Rate LimitとPod単位のLocal Rate Limitに機能を分割しました。これらの詳細は別のページで紹介しています。\n Rate Limitに関して Istio Ingress Gatewayに関して アクセスログに関して  Apacheを移行時のロードバランサーとして選定した理由 #   ApacheというL7ロードバランサーはRequest / Response Headerなどの処理をすでに抱えており、短期間で移植することは困難であることが想定されました。 ApacheよりもDown Stream側にあるロードバランサーをチームの権限でコントロールすることはできないため変更のリードタイムが長くなることが想定されました。 ApacheではなくnginxやHAProxyだったら移植できたかというとそういう問題でもなく、直接KubernetesクラスタでTrafficを受けたときにKubernetes自体やIstio Ingress GatewayがTrafficの負荷に耐えられるか、信頼できる負荷試験の結果が存在しないため、旧環境に切り戻すリスクが高いと判断しました。  すなわち、運用実績とオペレーションの容易さからApacheで移行することが移行時に取り得る選択肢として最良と判断しました。\n※ 結果は言わずもがなですが、書いてあるとおりスケジュール通りに移行を完遂させています。\n"},{"id":1,"href":"/docs/manifest/manifest-management/","title":"KubernetesのManifest管理","section":"Manifest管理","content":"Kubernetes の Manifest 管理 #  ここではManifestの管理をどのように実施しているかについて紹介します。 結果から言えば、Kubernetesで利用するManifestを生成するGeneratorをTypeScriptで構築しました。\nどのように構築して運用しているのか説明していきます。\n移行後の各Componentのファイル数の規模感 #  導入でも提示していますが改めて、フロントエンドに関係するマイクロサービスに関係するManifestは以下の規模で存在しています。 これは簡単に管理するとは言えないコンポーネント数があり、これからも増えていきまうｓ．\n   Component ファイル数     v1/Deployment 20   v1/Service 60   v1/Config Map 15   batch/v1/Job 15   argoproj.io/v1alpha1/Rollout 20   networking.istio.io/v1beta1/VirtualService 20   networking.istio.io/v1alpha3/EnvoyFilter 20    問題意識 #  移行前の段階ですでにファイル数はYAMLで保守するには困難な量が発生することはわかっており、ツールによる補完支援やテスト無しでは必ず破綻することが容易に想定されました。また、これらは最初に定めた2つの目標に反します。\n デプロイが素早く簡単にそして安全に実施できる Webnフロントエンド開発者が更新に必要な最低限の設定の変更を簡単に実施できる  TypeScriptでManifestの保守面の問題を解決する #  これらを網羅的に解決する一つの方法としてTypeScriptによりKubernetesのYAMLを生成することです。 TypeScript自体の利点は各種記事に譲るとして、Kubernetesを運用するチームの背景としてTypeScriptを日常的に利用しているWebフロントエンドのエンジニアたちです。\nしたがって、TypeScriptでManifestを記述すること自体は非常に障壁がほとんど皆無という状態です。 またManifest自体のテストもTypeScriptからYAMLを生成するタイミングでExceptionを投げてしまえば良いだけなので、テストの方針も非常に単純になります。\n仮にTypeScriptで書くのを辞めたいといった場合は生成されたYAMLを持っていけば良いので、TypeSCript自体を切り捨てることも簡単になります。\n以上の理由からTypeScriptで記述しない理由が移行の設計段階で存在しないため、ManifestをYAMLで書くことを初手で捨て、TypeScriptで記述するようにしました。\nTypeScriptでKubernetesを書くための支援ライブラリとSchema #  KubernetesはCustomResourceDefinitionを定義する際OpenAPI Schema V3で記述できます。 これによってSchemaがApply時にValidationされています。 逆に言えば、OpenAPI SchemaをTypeScriptの型定義に書き起こしてしまえばValidationをTypeScriptの静的型付けに変換することができます。\n幸いにして筆者はOpenAPI SchemaとTypeScriptの話にはちょっとだけ詳しいので、 手前味噌ですが@himenon/openapi-typescript-code-generatorを利用してKubernetesの型定義を生成しました。\n @himenon/kubernetes-typescript-openapi @himenon/argocd-typescript-openapi @himenon/argo-rollouts-typescript-openapi  もちろん他にも同じようなアプローチで型定義を提供しているものもありますが、以下の点で見送りをしています。\n TypeScriptのObjectに対してシンプルに型定義を当てたい  これはライブラリ側のメンテナンスが滞っても自分たちで書き直すことができるため   ArgoCDやArgoRollouts、Istioなど他のCustom Resource利用時も同じライブラリの使い勝手になるようにしたい 最新だけでなく任意の古いバージョンもサポートするようにする  これらを考えたときになるべくライブラリは薄く実装されているのが望ましく、型定義ライブラリをForkしたときも簡単にメンテナンスできる実装ベースが必要でした。これらの条件を満たす設計コンセプトで豊富な知見があるライブラリは@himenon/openapi-typescript-code-generatorでした。\n次の節でより詳細に紹介します。\n TypeScriptでKubernetesのmanifestを記述する TypeScriptでManifestを生成するGeneratorのアーキテクチャ  他のライブラリ #  Kubernetes向けTypeScriptのライブラリ\n cdk8s kosko  KubernetesのDefinitionが定義れているComponentはCustomResourceDefinitionがあります。\n"},{"id":2,"href":"/docs/manifest/kubernetes-manifest-written-by-typescript/","title":"TypeScriptでKubernetesのmanifestを記述する","section":"Manifest管理","content":"TypeScriptでKubernetesのmanifestを記述する #  ここでは基本的な書き方について紹介します。\n基本的な書き方 #  NodeJSで動かすスクリプトとして次のようなに記述してきます。 これをts-nodeなどで実行するとdeployment.ymlが出力され、kubectl apply -f deployment.ymlとすることでKubernetes上にPodが起動します。\nimport * as fs from \u0026#34;fs\u0026#34;; import * as yaml from \u0026#34;js-yaml\u0026#34;; import type { Schemas } from \u0026#34;@himenon/kubernetes-typescript-openapi/v1.22.3\u0026#34;;  const podTemplateSpec: Schemas.io$k8s$api$core$v1$PodTemplateSpec = {  metadata: {  labels: {  app: \u0026#34;nginx\u0026#34;,  },  },  spec: {  containers: [  {  name: \u0026#34;nginx\u0026#34;,  image: \u0026#34;nginx:1.14.2\u0026#34;,  ports: [  {  containerPort: 80,  },  ],  },  ],  }, };  const deployment: Schemas.io$k8s$api$apps$v1$Deployment = {  apiVersion: \u0026#34;apps/v1\u0026#34;,  kind: \u0026#34;Deployment\u0026#34;,  metadata: {  name: \u0026#34;nginx-deployment\u0026#34;,  labels: {  app: \u0026#34;nginx\u0026#34;,  },  },  spec: {  replicas: 3,  selector: {  matchLabels: {  app: \u0026#34;nginx\u0026#34;,  },  },  template: podTemplateSpec,  }, };  const text = yaml.dump(deployment, { noRefs: true, lineWidth: 144 }); fs.writeFileSync(\u0026#34;deployment.yml\u0026#34;, text, \u0026#34;utf-8\u0026#34;); TypeScriptで記述する特徴 #  TypeScriptで記述したときの特徴を紹介します。\nYAMLの記法に悩まれなくて済む #  まず一番わかりやすいのはYAMLの記法のブレがなくなります。 YAMLは出力された結果であり、その結果を出力する処理が記法を規格化するためYAMLの記法に関する一切のレビューが不要になります。\n spaceかtab indentか indentはspace 2か4か 複数行コメントは|か\u0026gt;のどちらで初めるか アルファベット順にソートするか  など。これらのことを一切考える必要がありません。\nコメントが書きやすい #  TypeScriptのコードコメントがそのまま利用することができます。 エディタ上で変数名などをホバーしたときにコメントが見えるなどの可視化支援を受けることができます。\nまた、そのままドキュメントになるためマニフェストとドキュメントの乖離を防ぐことができ、ロストテクノロジーになることに対する予防措置が同時に実施できます。\n/** podTemplateに対するコメント */ const podTemplateSpec: Schemas.io$k8s$api$core$v1$PodTemplateSpec = {};  const deployment: Schemas.io$k8s$api$apps$v1$Deployment = {  apiVersion: \u0026#34;apps/v1\u0026#34;,  kind: \u0026#34;Deployment\u0026#34;,  metadata: {  name: \u0026#34;nginx-deployment\u0026#34;,  labels: {  /** このラベルを付ける理由.... */  app: \u0026#34;nginx\u0026#34;,  },  },  spec: {  /** replicasが3で妥当な理由... */  replicas: 3,  /** このSelectorを付ける理由.... */  selector: {  matchLabels: {  app: \u0026#34;nginx\u0026#34;,  },  },  template: podTemplateSpec,  }, }; 「変数」が依存関係を表す様になる #  Kubernetesで基本的なServiceとDeploymentというセットを考えたとき、Service間通信するためにはServiceのSelectorをPodのLabelと一致させる必要があります。これをTypeScriptで表現する場合、SelectorとLabelの部分を変数化してしまえば確実に疎通ができるServiceとDeploymentのマニフェストを生成することができます。\n他にも推奨されるラベルにあるapp.kubernetes.io/versionなども漏れなく適切に指定されるようになります。\nconst Namespace = \u0026#34;mynamespace\u0026#34;;  export const generateService = (applicationName: string, applicationVersion: string): Schemas.io$k8s$api$core$v1$Service =\u0026gt; {  return {  apiVersion: \u0026#34;v1\u0026#34;,  kind: \u0026#34;Service\u0026#34;,  metadata: {  name: applicationName,  namespace: Namespace,  },  spec: {  type: \u0026#34;ClusterIP\u0026#34;,  selector: {  app: applicationName,  \u0026#34;app.kubernetes.io/name\u0026#34;: applicationName,  },  ports: [  {  name: `http-${applicationName}-svc`,  port: 80,  targetPort: 80,  },  ],  },  }; }   export const generateDeployment = (applicationName: string, applicationVersion: string): Schemas.io$k8s$api$apps$v1$Deployment =\u0026gt; {  return {  apiVersion: \u0026#34;apps/v1\u0026#34;,  kind: \u0026#34;Deployment\u0026#34;,  metadata: {  name: applicationName,  namespace: Namespace,  labels: {  app: applicationName,  \u0026#34;app.kubernetes.io/name\u0026#34;: applicationName,  },  annotations: {},  },  spec: {  selector: {  matchLabels: {  \u0026#34;app.kubernetes.io/name\u0026#34;: applicationName,  },  },  /** 省略 */  },  }; }  const applicationName = \u0026#34;my-nginx\u0026#34;; const applicationVersion = \u0026#34;1.14.2\u0026#34;;  generateService(applicationName, applicationVersion); generateDeployment(applicationName, applicationVersion); テンプレートの表現力が増す #  例えばNodeJSやGo Lang、Scalaなど様々な言語で記述されているマイクロサービスの基本的なDeploymentのテンプレートなども用意できるようになります。これは例えば/aと/bのエンドポイントが同じサーバーから提供されているが、水平スケールする単位やCPU/MEMなどの各種リソースを分離して管理したい場合にManifestを分割したい場合に大いに役立ちます。うまくManifestのGeneratorが設計されていれば数分のオーダーで分割ができ、即日デプロイすることができます。\nexport const generateNodeJsDeployment = ():Schemas.io$k8s$api$apps$v1$Deployment =\u0026gt; {}; export const generateRubyOnRailsDeployment = ():Schemas.io$k8s$api$apps$v1$Deployment =\u0026gt; {}; export const generateScalaDeployment = ():Schemas.io$k8s$api$apps$v1$Deployment =\u0026gt; {}; Generator内部でErrorをthrowすることがテストになる #  ManifestをGenerateする際に立地なテストフレームワークは不要で、単純にExceptionを発生させることがテストになります。 例えばServiceやJobなどのリソースタイプはmetadata.nameに指定可能な文字列や文字数が決まっています（参照）。\n大きな変更が入った後にkubectl applyを実施して、この問題が発覚するとトラブルシュートの時間が掛かるため、ManifestをGenerateする際に具体的なエラーメッセージを出力して処理を中断してしまえば悩む時間が最小限にできます。 手元でGenerateせずにPull Request投げた場合はCIでGenerateを再度走らせてテストを実施することができます。\nexport const validateMetadataName = (text: string, throwError?: true): string =\u0026gt; {  if (throwError \u0026amp;\u0026amp; text.length \u0026gt; 63) {  throw new Error(`May not be deployed correctly because it exceeds 63 characters.\\nValue: \u0026#34;${text}\u0026#34;`);  }  return text.slice(0, 63); };  export const generateJob = (applicationName: string): Schemas.io$k8s$api$batch$v1$Job =\u0026gt; {  return {  apiVersion: \u0026#34;batch/v1\u0026#34;,  kind: \u0026#34;Job\u0026#34;,  metadata: {  name: validateMetadataName(applicationName, true),  },  }; }; "},{"id":3,"href":"/docs/manifest/kubernetes-manifest-generator-architecture/","title":"TypeScriptでManifestを生成するGeneratorのアーキテクチャ","section":"Manifest管理","content":"TypeScriptでManifestを生成するGeneratorのアーキテクチャ #  アーキテクチャが解決すること #  そもそも Generator そのものが解決することは manifest をドキュメントの乖離を防ぎ、YAMLの記法のぶれなどを防ぐことです。 アーキテクチャが解決しなければいけないことは、具体的には次のようなことが挙げられます。\n マニフェスト自体のスケーラビリティを確保する 実際に運用する際に必要最小限の変更だけで Manifest を更新できる ≒ 宣言的な変更で済むようにする マイクロサービス単位で設定の変更ができる（CPU/MEM/replicas など） 管理しているマイクロサービス全体のリソース量、変更時の増減が把握できる Manifest ファイルの命名規則、出力先のディレクトリ・ファイルツリーなどを意識しなくても良い Generator 自体の保守性を高める  これらを表現するためのアーキテクチャはStatic Site GeneratorやYeoman、Cookiecutter、Rails Scaffoldなどたくさん事例があります。 これらの基本的な骨格をKubernetesのManifest Generatorとして応用し次のようなアーキテクチャが設計しました。\nそれぞれの役割を紹介します。\n   名称 役割     User Config バージョン変更など最小限の変更を与えるファイル   Kubernetes TypeDefinition TypeScriptの型定義   MicroService Template マイクロサービスの種類に応じたテンプレート   Definition Namespace名やPort番号、Gatewayの Host 名などの不動値の定義   Resource ParameterとMicroService Templateを Kubernetes のリソースコンポーネント単位で結合する   Factory Resourceをどのファイル名でどのグループで出力するか定義する   Writer Factory から与えられた情報から Kubernetes の Manifest や、CPU Requests などのレポートを生成する    具体的な実装例 #  実装サンプルを以下のリポジトリに用意しました。nodejsとpnpmを利用したサンプルとなっています。 Docker Swarmを利用すればArgo Rollouts + Istioがデプロイできるところまで確認しています。\n https://github.com/Himenon/kubernetes-template     Name PATH     User Config config/*.json   Kubernetes TypeDefinition src/k8s/*   MicroService Template src/templates/*   Definition src/definitions/*   Factory src/factory/*/index.ts   Resource src/factory/*/resource.ts   Writer src/writer/*    依存関係はsverweij/dependency-cruiserのカスタムルールによってテストしています。\n https://github.com/Himenon/kubernetes-template/blob/main/.dependency-cruiser.js#L4-L94  Writerが出力するファイルは以下の通り。\n kubectl apply -k overlays/[env]/が可能なディレクトリ群  https://github.com/Himenon/kubernetes-template/tree/main/overlays   productionで利用するリソースのレポート  https://github.com/Himenon/kubernetes-template/blob/main/report/resource-table.md    特徴的なこと #  ConfigMapの更新した後にPodを再起動する #  例えばDeploymentがConfigMapの設定によって動作を変化させるような場合、ConfigMapだけを更新してもロールアウトは発生しません。\n Deploymentのロールアウトは、DeploymentのPodテンプレート(この場合.spec.template)が変更された場合にのみトリガーされます。例えばテンプレートのラベルもしくはコンテナーイメージが更新された場合です。Deploymentのスケールのような更新では、ロールアウトはトリガーされません。\n引用: Deploymentの更新\n これを対処するには例えばConfigMapのContentHashを計算して、 それをPod TemplateのAnnotationに付与することでConfig MapとDeploymentの関係性を作れます。\nimport { createHash } from \u0026#34;crypto\u0026#34;;  export const createContentHash = (text: string): string =\u0026gt; {  const hash = createHash(\u0026#34;md4\u0026#34;);  hash.update(text);  return hash.digest(\u0026#34;hex\u0026#34;); }; kind: Deployment spec:  template:  metadata:  annotations:  # Content Hashの値は依存するConfigMapに対して計算する。  dependency.config-map.content-hash: bf84e528eaedf3fd7c3c438361627800 これのApplyの順番はArgo CDのSync Waveを利用すると簡単に制御できます。\nReportを作成するスクリプトはNonNull Assertionを許可する #  TypeScriptで書いてると厳密に型定義を守ることが開発の安全に繋がりますが、Writerの種類によっては2つの理由でこれを許容します。\n 細かく定義するコストが高い レポートとして自動生成するようなパラメーターは\u0026quot;そもそも必須\u0026quot;であるため、マニフェスト生成時にエラーになってくれたほうが良い  前者は消極的な理由ですが、後者は先程紹介した実装内でExceptionを発生させると同じ意味合いを持っています。 つまり、obj.a?.b?.cで参照するよりもobj.a!.b!.c!で参照すると、型チェックしてthrow new Errorをする手間が省ける算段です。 もしくは、生成されたレポートがおかしな状態になるのでレビューで簡単に防ぐことができます。\n 実装例  Manifest生成はどう使うのがよいか？ #  リポジトリ運用について #  namespace単位で管理するのが楽でしょう。ただし、機密情報がある場合はsecretだけまとめたリポジトリを別途切るのは必要です。 namespace内は基本的に競合する.metadata.nameを作ることはできません、加えて仮に同じ名前にしても管理が複雑になります。\nツールについて #  ここで紹介したのは、愚直にKubernetesなどが提供しているOpenAPI Schemaから型定義を生成したものを利用した例でした。 KubernetesのドキュメントにはREST API経由でKubernetes APIをCallするClient Libraryとしていくつか紹介されています。\n https://kubernetes.io/docs/reference/using-api/client-libraries/  これを純粋にREST APIのClientとして使うだけでなく、Manifestを生成するために役立てることも可能でしょう。 YAMLで書くには複雑になりすぎた場合に、チームで使い慣れた言語で記述する選択肢も用意されているので一考する価値はあるでしょう。\nGeneratorを辞めたくなったら #  YAMLだけ残して後の実装はさっぱり捨ててしまいましょう。YAMLだけあればKubernetesにデプロイは可能ですから。\n"},{"id":4,"href":"/docs/ci/argo-cd/","title":"Argo CDの利用","section":"Continuous Delivery","content":"Argo CD #  ニコニコ生放送のフロントエンドではContinuous Delivery(以降CD)ツールとしてArgo CDとArgo Rolloutsを利用しています。 ここでの運用とその設計について紹介します。\n注意書き\n argoproj.io/v1alpha1/Applicationのことを「ArgoCDのApplication」と表記します。  他チームとの棲み分け #  Argo CDはフロントエンドのチームだけではなく、他のチームが管理するものも存在しています。 したがってチーム横断で管理している部分が存在するとレビューコストが上がるため、App of Apps Patternsを利用して管理するArgocd Applicationをフロントエンドチームのnamespaceで分離しました。\n具体的にはapp of appsを2段階で利用して次の図ように分離しています。\n図中のRoot ArgoCD Appsは他チームと干渉する部分になっています。 ここに、フロントエンドチームが管理するArgoCD Appsを配置します\napiVersion: argoproj.io/v1alpha1 kind: Application metadata:  name: frontend-apps  finalizers:  - resources-finalizer.argocd.argoproj.io spec:  project: default  source:  targetRevision: master  repoURL: # フロントエンドチームが管理するapp of appsパターンの親リポジトリ  path: kubernetes/overlays/[環境名]  destination:  server: https://kubernetes.default.svc  namespace: argocd  syncPolicy:  automated: {} これにより、ArgoCD上で他チームと干渉する場所が木の間にマニフェストファイルが絞り込まれました。\nフロントエンドのチームが管理するマイクロサービスのためのリポジトリとArgoCDのApplication設定 #  フロントエンドチームが管理するマイクロサービスのManifestは2つのリポジトリで管理しています。\n secret infrastructure  secretはKubernetesのSecretに対応するコンポーネントを格納するリポジトリで、機密情報が含まれるため権限がなければRead/Writeできないリポジトリ設定です。 infrastructureのリポジトリはフロントエンドチームが管理するすべてのマイクロサービスのManifestが集約されています。\ninfrastructureは具体的には次のようなディレクトリ構成になっています。\nkubernetes/overlays ├── production │ ├── app1 │ ├── app2 │ ├── ... │ ├── ... │ └── appN ├── [env2] ├── [env3] ├── ... ├── ... └── [envN] ├── app1 ├── app1 ├── ... ├── ... └── appN もう少し平たく書くと、\nkubernetes/overlays/[デプロイ環境]/[マイクロサービス名] したがって、フロントエンドのチームが管理するArgoCDのapp of appsの親は次のようなArgoCDのApplicationがそれぞれのパスを散所するようにずらっと並んでいます。\napiVersion: argoproj.io/v1alpha1 kind: Application metadata:  name: datadog  finalizers:  - resources-finalizer.argocd.argoproj.io  annotations:  notifications.argoproj.io/subscribe.slack: \u0026#34;Slack Channel Name\u0026#34;  argocd.argoproj.io/sync-wave: \u0026#34;-100\u0026#34; spec:  project: default  source:  repoURL: [REPOSITORY URL]  targetRevision: master  # ここのパターンの分だけファイル数がある  path: kubernetes/overlays/[デプロイ環境]/[マイクロサービス名]  destination:  server: https://kubernetes.default.svc  namespace: frontend  syncPolicy:  automated: 一見するとファイル数はとても多くなりますが、TypeScriptでManifestを生成しているため、ファイル数の量は問題ではありません。\nフロントエンドが管理するマイクロサービスのためのManifestのリポジトリ #  前節ですでに先んじで登場していますが、infrastructureのリポジトリ内にフロントエンドチームが管理するマイクロサービスのすべてがあります。\nまず、infrastructure各マイクロサービスのリポジトリ（NodeJSなどの具体的な実装）からは分離されています。 これはBest Practiceに則っています。\n次に、1つのリポジトリでチームが管理するすべてのManifestが存在している理由は次の点が挙げられます\nメニーレポで管理しない理由 #   メニーレポ（複数のリポジトリ）で管理すると保守するときの更新が大変である  モノレポで管理する理由 #   全体最適化が容易になる Webフロントエンドのアプリケーションは1つのhostに対してルーティングが存在するため全体を見て調整するケースが有る  後述しますがGlobal RateLimitなどがその例   1つのマイクロサービスに複数のルーティング先が存在するが、デプロイ単位として分割したい場合の管理  これらはWebフロントエンドの開発時にnpmパッケージをモノレポで管理しているところからの発想もあり、モノレポのほうが開発や保守効率が圧倒的に早いことが経験則としてわかっていることも決め手の背景としてあります。\nSlack Botによる自動化で改めて紹介しますが、結果的にモノレポで管理した事によってBotによる更新が容易になり、マニフェストの変更から本番デプロイまでが5分以内で終わるスピーディなリポジトリなっています。もはやBotユーザーしかリポジトリの更新をしていない状態です。\ninfrastructureリポジトリのブランチ設計 #  マイクロサービスをKubernetesクラスターにデプロイするためのブランチは以下の2つしか用意していません。\nmaster .... 開発環境にリリースされるブランチ（Defaultブランチ） release/production .... 本番リリース用のブランチ kustomizeが提案するブランチ運用の場合、各環境ごとにデプロイするブランチが存在しますが、開発環境においてはDefaultブランチにマージした場合はすべての開発環境に問答無用でデプロイされるようにしています。\n理由はいたって単純で、デプロイする環境数が多く、わざわざ各環境用にデプロイするためのPull Request作成からマージまでのリードタイムは非常に遅いと判断したためです。\nmasterブランチはSquash Mergeのみ許容する #  モノレポにしていることもありたくさんのPull Requestがinfrastructureリポジトリに飛んできます。 するとcommit履歴も比例して多くなります。 通常Merge CommitでGitHubのPull Requestを処理した場合、Pull Request中で変更した内容とMerge pull requestのコミットが一気に追加されるため、 GitOpsを運用しているリポジトリでこれを実施するとcommit履歴が単純に荒れます。 これを防ぐため、masterブランチに対するマージはSquash Mergeのみを許可し、必ずPull Request一つに対してcommitが1つになるように実施しています。\nまた、release/productionブランチに関してはリリース用のブランチであるため、こちらはMerge Commitのみを許容しています。Squash Mergeを実施した場合はmasterに対してバックポート処理が必要になるためです。 さらに、2つのブランチで異なるMerge方法をGitHuのルールで強制することができないため、Slack Botによるマージ処理の自動化も実施しています。\nmasterブランチに入ったものは必ずいつでもリリースして良いものとして扱う #  manifestをモノレポで運用しているため、共生している他のマイクロサービスが別のマイクロサービスと同時にリリースされる可能性があります。 すなわち、本番環境にリリースしたくない変更はmasterブランチに入れなければ良いだけになります。 また、特定の環境だけバージョンを上げたいときの手続きが長いといった要望は明らかに予想可能な問題なため、同時にSlack Botによってデプロイの簡略化と自動化を実現しています。\nrelease/productionブランチに対してPull Requestを投げたとき同時にtagとリリースノートを作成する #  release/productionに対するPull Requestは不可逆の処理として扱います。 リリースすべきでない変更が入っている場合はmasterにコミットした後、改めてrelease/productionに対してPull Requestを投げます。 このときもtagとリリースノートを同時に作成します。 すでに切られたtagやリリースノートは削除せずどんどん新しいものを使っていく運用になっています。 tagやリリースノートを削除して新しく新規のバージョンで切る方法もありますが、これはたくさんの変更を受け付ける際にコンフリクトしやすく、 運用が難しいため、運用が簡単で速度が出やすい欠番方式を採用しています。\nデプロイの速度が重要な理由 #  ここまで紹介してきた方法はすべて「デプロイの速度を落とさないため」に実施しています。 速度に拘る理由は、「遅くする理由がないから」です。 Kubernetes上で障害が発生したときは一時的にCLIや管理用のDashboardからRollbackの処理などを実施することができます。 しかしながらそれだけでは対応できない構成変更やアプリケーションの再投入が必要な場合に、デプロイの部分が遅ければそれだけ影響の受けるユーザーが多く、損失も大きくなります。 逆コンウェイの法則然り、最速でデプロイできるフローに運用の手続きをあわせていくことがこの場合、あらゆる面で有効であるため、最速のデプロイフローを作ることに拘っています。 こう見ると安全にデプロイできるかという話がありますが、それは自動化によって対処すべき話であるため別途紹介します。\n"},{"id":5,"href":"/docs/ci/argo-rollouts/","title":"Argo Rolloutsの利用","section":"Continuous Delivery","content":"Argo Rolloutsの導入 #  Argo Rolloutsとは #  Argo RolloutsはKubernetes上にPodをデプロイする方法の選択肢を増やしてくれます。 Blue/Greenデプロイ、Canaryデプロイ、Progressive Deliveryなど。\nとくにTraffic Managementを利用したデプロイ方法は非常に魅力的で、利用しない理由は見当たりませんでした。 ちょうどArgo Rolloutsがv1系が利用可能な状態で、移行時の検証と同時に必要な機能が使えることを確認できたため導入しました。\n 2021/05 v1.0.0 2021/10 v1.1.0 2022/03 v1.2.0  Istio + Argo Rollouts #  Istio自体はすでに利用可能な状態にあったため、Traffic Managementを実施するLoadBalancerはIstioを利用しています。\n Istio - Traffic Management  他と比較はできていませんが、IstioでTraffic Managementをすると、IstioのService Meshの恩恵をそのまま得られることができCanaryデプロイ時にTraffic Weightが変化していることが観測できるようになります。 なお、Istio Ingress Gatewayの設定でその他の機能についても紹介しています。\nCanary Deployを実施する #  RolloutのManifestは.spec.strategy以外の部分はDeploymentと同じです。\napiVersion: argoproj.io/v1alpha1 kind: Rollout metadata:  name: my-app spec:  strategy:  canary:  trafficRouting:  istio:  virtualService:  name: my-app  routes:  - http-my-app-primary  maxSurge: 33%  canaryService: my-app-canary  stableService: my-app-stable  dynamicStableScale: true  steps:  - setCanaryScale:  matchTrafficWeight: true  - pause:  duration: 60  - setWeight: 34  - setCanaryScale:  matchTrafficWeight: true  - pause:  duration: 60  - setWeight: 67  - setCanaryScale:  matchTrafficWeight: true  - pause:  duration: 60  - setWeight: 100 特徴的なのはcanaryServiceとstableService用に2つのService定義が必要になるところです。 Rolloutsに定義されたServiceは\n.spec.selector.rollouts-pod-template-hash: \u0026#34;HashValue\u0026#34; がArgo Rolloutsによって付与されます。またPodの更新時にReplicaSetにも\n.spec.selector.matchLabels.rollouts-pod-template-hash: \u0026#34;HashValue\u0026#34; が指定され、Canary用のServiceとStable用のServiceのエンドポイントが区別されています。 あとはIstioのVirtual ServiceのTraffic Weightに対する変更がStep単位で記述することが可能です。\n注意点 #  Argo RolloutsはDashboardではPromote Fullというボタンがあります。 これを利用した場合、stepを無視してPromotionの最終状態まで到達します。 つまり、トラフィックを受け付ける準備ができていないPodに対してもトラフィックが流れるため、使う場面を見極める必要があります。\n Argo Rollouts v1.2.0で確認  Traffic Weightに応じたReplicasを指定する #  .spec.strategy.canary.steps[].setCanaryScale.matchTrafficWeight = true を指定することで、.spec.replicasを100%ととしたReplicasがTraffic Weightに比例してPodが配置されます。\nまた、setCanaryScale.replicasと併用して指定している場合は、CanaryのreplicasはRolloutsのmanifestで指定した値に必ずしもならず、Traffic Weightで算出されたCanaryのReplicasと手動で指定したReplicasのTrafficに耐えられるうち安全な方が優先されて指定されます。\n https://github.com/argoproj/argo-rollouts/blob/v1.2.0/utils/replicaset/canary.go#L331-L353  Canary Deploy時トラフィックが流れていないPodを縮退させる #  以下のフラグを有効にすることで実現できます。\n.spec.strategy.canary.dynamicStableScale = true これにより、replicasとTraffic Weightを同時にコントロール可能な状態になります。\nDataDogでのモニタリング例 #  あるマイクロサービスのPodに対するRequest Per Secをバージョンで分類して、 Rolloutsによる更新をモニタリングすると次のようにTrafficが変更されていることがわかります。\n同様にCPUの使用率も確認すると、たしかにRolloutsで定義したStep通りにPodは増加し、 Trafficが流れなくなったPodは徐々に終了していることが確認できます。\nこれから #  Argo RolloutsはProgressive Deliveryを実現する方法を提供しており、DataDogとの連携も容易にできることがわかっています。\n https://argoproj.github.io/argo-rollouts/analysis/datadog/  これを実現するために、今現在は各種Metricsの集計とその信頼性の検証を進めています。 BFFのマイクロサービスの安定性を表すための定量的な指標を集計値として表せてはじめてこの機能を有効にできるため、 運用の実績値を蓄積し、集計し、不足しているMetricsを追加する作業を繰り返し行っています。\n"},{"id":6,"href":"/docs/ci/slack-bot/","title":"Slack Botによる自動化","section":"Continuous Delivery","content":"Slack Botによる自動化 #  Argo CDによるGitOpsの実現は同時にGitOpsを開発者に強制します。 すなわち、バージョンアップのためのcommitを実施し、Pull Requestを投げ、マージする必要があります。 更新頻度の多いアプリケーションを抱えた場合、この作業が非常に長く開発者の体験を悪くします。\nそこで、Slack Botサーバーを作成しSlackにメッセージを入力することで手続き的なタスクをサーバー側に実施するようにしました。\nバージョンアップのシーケンス図 #  シーケンス図を使って紹介します。 バージョンアップの手順はSlack上でBotに対して次のようなコマンドを投げることから始まります。\n# server-aをバージョン2.0.0に変更する @bot update version:2.0.0 app:servive-a これを受け取ったbotサーバーは、メッセージの入力者を判別したり、コマンド(update version)をパースしたりします。コマンドに応じてGitHub APIをCallし、JSONで記述されたファイル(User Config)を書き換え、commitします。 その後Pull Requestを作成して、結果をユーザーに返します。\n作成されたPull RequestをさらにSlackからマージします。\n@bot merge pr:123 これをシーケンス図で書き起こすと次のようになります。\n基本的な操作はすべてSlack上から実施が可能で、開発者がバージョンアップのためにリポジトリをCloneして環境構築する必要はありません。\n既存のアプリケーションのCIとKubernetes Manifestのリポジトリの連携 #  Slack Botによって自動化されたKubernetesのManifestリポジトリは既存のリリースフローとも結合が容易になります。\n例えば、アプリケーションにバージョンアップのCIタスクがあった場合、次のバージョン情報をSlackのWebhookを利用して先程と同じようにメッセージをBotに対して送るだけで結合できます。\n# 擬似コード message=\u0026#34;{\\\u0026#34;text\\\u0026#34;:\\\u0026#34;@bot update version:${nextVersion}app:service-a\\\u0026#34;}\u0026#34; curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data $message https://hooks.slack.com/services/{your_id} 大抵のサーバーはcurlかそれに類するHTTP Clientを用意できるため、たった2行挿入するだけでデプロイの簡略化ができます。\nSlack Botによってデプロイ作業を最小工数で終わらせる #  バージョンアップのコマンドを紹介しましたが、他にも10個程度のコマンドがあります。\n リリース準備用のコマンド 最新のリリース情報の取得 次に投入される予定のバージョン情報の取得（差分） リリース用のチケット作成 リリースノート更新  など、リリースに関する一連の情報や作業が細かくできるようになっています。 特に、差分情報やリリースノートの作成などを自動で実施しているためリリースの影響範囲が単純明快になるため確認コストが最小限になっています。\nまた、Slackのメッセージ経由で実施しているためBotサーバーが失敗した場合でも何がやりたかったのか証跡がSlack上に残ります。 再実行を実施するのももう一度メッセージをコピー\u0026amp;ペーストするだけの作業になります。\n"},{"id":7,"href":"/docs/service-mesh/istio/","title":"BFFとIstio","section":"Service Mesh (Istio)","content":"BFFとIstio #  Istio の利用 #  Istio は既存のマイクロサービスに対して後付で導入することができ、 通信を可観測にしたり、負荷分散を実施したり、Proxy としての機能を持っています。 Kubernetes 上で稼働するマイクロサービスの通信をよりプログラマブルに扱える機能を提供しています。\n実際に触ってみると istioが謳っているこれらの機能は有用で、サービスメッシュはKubernetesを運用する上で必要不可欠であることを実感させられます。\nさて、詳細な部分はドキュメントを読むのが望ましいですが、とっつきにくい部分もあるのでフロントエンドのエンジニアが使うと便利な機能を紹介しつつ Istio のコンポーネント紹介します。\nIstioとEnvoyの関係 #  まずはIstioとEnvoyの関係について知っておく必要があります。\nEnvoyはそれ自体がProxyであり、nginxやApacheなどのL7 LBと似たような機能を提供しています。 大きな違いとして、Envoy はテレメトリが標準で豊富だったり、APIによる構成変更が可能だったりプログラマブルにコントロールできる機能を豊富に持っています。 すなわち再起動をせずに構成変更が容易であり、Argo RolloutsのCanary Deployで紹介したように Traffic Weight を柔軟に変更することが可能になります。\nIstioはこのEnvoyを利用して、Kubernetes上で稼働するマイクロサービス間の通信を観測するために Control Plane から各 Pod に Sidecar として注入します。 Istioから提供されているEnvoyのDocker Imageはistio-proxyという名前で提供されており、kubectl get pod [podname]などで構成を確認するとistio-proxyという名前を確認することができます。\nEnvoy 単体では通常以下のような YAML を記述して起動時に読み込ませることで Envoy の設定変更を実施します。\n https://www.envoyproxy.io/docs/envoy/latest/configuration/overview/examples  Istio の場合、Envoy はすでに起動された状態で存在しているため、既存の設定が存在しています。 そのため、この構成変更をしたい場合はEnvoyFilterを利用します。\n https://istio.io/latest/docs/reference/config/networking/envoy-filter/  ただ普段書くような Traffic Management 用の設定は別のコンポーネントを利用して簡易に記述することができます。\n   Component 名 役割     Gateway 受け入れ可能なホスト名、ポート番号、プロトコルなどを記述する   Virtual Service PATH単位のルーティングの設定が可能。Traffic Weight の指定、Header や Query Parameter による個別のルーティング先もここで指定する。   Service Entry Kubernetes クラスタから外部へのアクセス制限など。    その他（https://istio.io/latest/docs/reference/config/networking）にもComponentはありますが最初に指定するものはおおよそ上記の3つでしょう。\nIngress Gatewayをセットアップする #  IstioはSidecarにistio-proxyを注入するだけではなく、Ingress Gatewayを作成することでその機能をより活かすことができます。\nIngressGatewayはnamespaceやKubernetesの境界に位置するGatewayとして機能させることで管理下にあるマイクロサービスに対するアクセスの制御ができます。 Webフロントエンドが管理するような、Internetからアクセスされ、他マイクロサービスから直接CALLが必要ないマイクロサービスはIngress Gatewayを通して管理すると負荷対策やデプロイの運用が楽になります。\nIstioにおけるIngress GatewayのセットアップはIstioOperator利用して実施します。\n https://istio.io/latest/docs/setup/install/operator/  istio-system以外のnamespaceでIstioOperatorが利用できるようにする #  IstioOperatorの管理をnamespaceを分けて管理したい場合、デフォルトの設定のままではインストールすることができません。例えば以下のようにIstioOperator(Deployment)をセットアップするとwatchedNamespacesで指定されたistio-systemでのみIstioOperatorのコンポーネントが利用できません。\n$ helm install istio-operator manifests/charts/istio-operator \\  --set watchedNamespaces=istio-system \\  -n istio-operator \\  --set revision=1-9-0 すでにインストールされた環境下の場合、次のようなコマンドでIstioOperatorが利用可能なnamespaceを確認することができます。\nkubectl get deployment -n istio-operator -l operator.istio.io/component=IstioOperator -o yaml | grep -A1 \u0026#34;name: WATCH_NAMESPACE\u0026#34; 環境変数WATCH_NAMESPACEを更新することでIstioOperatorのコンポーネントが利用することができるようになります。 例えばmyteamというnamespaceを追加したい場合は次のように実施します。\nkubectl set env deployment/istio-operator-1-11-4 WATCH_NAMESPACE=\u0026#34;istio-system,myteam\u0026#34; -n istio-operator Ingress Gatewayの具体的な設定は次の節で紹介しています。\nistio-proxyのサイドカーが不要なケース #  Job #  Istioを有効にした場合Podに対してistio-proxyがsidecarとして挿入されます。 しかしながら、不要なケースも存在します。 1回だけ実行されるJobとして実行されるPodはJobが終了したするとPodのStatusがCompletedになりますが、istio-proxyは常駐するサーバーであるためJobがCompletedになりません。\nそのため、JobはPod Templateに対してsidecar.istio.io/inject: \u0026quot;false\u0026quot;を指定することでSidecarを注入させないようにしています。\napiVersion: batch/v1 kind: Job metadata:  name: myjob spec:  template:  metadata:  annotations:  sidecar.istio.io/inject: \u0026#34;false\u0026#34;  # 省略 BFFでサービスメッシュが有効だと何が良いか #  最も嬉しいのは可観測性にあります。 BFFはその特性上、各マイクロサービスから情報をかき集め、場合によってはServer Side Rendering(SSR)を実施します。 最終的な結果はユーザーに届くため、一連の処理がユーザー体験に直接影響します。 ゆえに、明らかにレスポンスタイムが悪いマイクロサービスがある場合いくつかの行動を取ることができます。 特定のバージョンから悪化しているのであればロールバックを実行したり、 Client Side Rendering可能な情報であれば最初のHTMLを構成するためのクリティカルパスから除外したりすることが可能です。 少なくとも、継続的な監視は問題を明確にし、物事の優先度を合理的に決定することができます。 負荷試験やモニタリングの節で具体的なMetricsの可視化を紹介しています。\n"},{"id":8,"href":"/docs/service-mesh/access-log/","title":"アクセスログ","section":"Service Mesh (Istio)","content":"アクセスログ #  Webフロントエンドが管理するサーバーにおける最重要なシステムの一つはアクセスログです。 不正アクセスなどのセキュリティ的な側面や、会社の収益のツリー構造に関わる部分など多くの重要な情報をここから得られます。 ゆえにこの部分のシステムは信頼度が最も高い方法で実現する必要があります。\nしたがって移行前のアーキテクチャをなるべく踏襲しつつ、Ingress Gatewayに近いところに配置する必要がありました。 また、ログは既存のfluentdの収集と連携する必要がありました。\n最終的に本番で稼働しているアーキテクチャは次のようになります。\nIngress Gatewayとアクセスログ周りのアーキテクチャ #  戦略としてはIngress Gatewayの前段にnginxを配置し、クラスター外からのアクセスを最初にnginxが受けるようにしました。nginxから出力されるアクセスログはsyslogでUnix Socketを経由してfluent-bitに転送しています。 fluent-bitはsyslogをINPUTとして既存のfluentdと結合するために出力先のディレクトリとログの書き出しをコントロールしています。\nこのアーキテクチャに至った経緯を紹介します。\nアクセスログの出力にnginxを利用している理由 #  今回は移行が伴っているため、なるべく低コストで移行を安全に実施したい狙いがありました。 もともとnginxからログを出力していることもあり、その実績からそのまま流用する形を取りました。\nまた、envoyによるアクセスログの出力も考慮に入れましたが、Cookieなどに含まれる情報を出力するためにluaを書く必要があったり、そのパース用にスクリプト自体が保守するのが大変であるため断念しました。\nfluent-bitで収集してfluentdに渡している理由 #  fluentdは移行前からあるログ収集の手段です。 fluent-bitはfluentdのC言語実装で、fluent-bitも出力先をfluentdと同じ場所に向けることは可能です。 しかしながらこれも移行をスムーズに進めるために既存のfluentdの設定を頑張ってfluent-bitに移すことはしませんでした。\nnginxからfluent-bitにUnix Socket経由でログを送信している理由 #  最初、fluent-bitをDaemonSetとして配置してIngress Gateway用のNodeに配置するようにしていました。 nginxのログをstdoutで出力し、/var/log/containers/[containerId].logに出力されるnginxのログをfluent-bitのtail INPUTを利用して収集していました。\nしかしながら、高rps環境下でtailを利用するとfluent-bitのtailが突然止まる不具合に遭遇しました。 これはissueに起票されていますが、活発でないとしてBotによって2022/04/09クローズされました。\n https://github.com/fluent/fluent-bit/issues/3947  挙動を見ているとどうやら/var/log/containersに出力されるログファイルのシンボリックリンク先である、 /var/log/pods/[pod-id]/0.logが.gzファイルにアーカイブされるときにファイルディスクリプタあたりが変更されそこでうまくfluent-bitが処理で基底なさそうだということがなんとなくわかっています。 とはいえこれを修正するためにfluent-bitにPull Requestを送って、リリースされるまでの間ログが収集できないとなると移行スケジュールに問題が発生するため別の方法を考えました。\n幸い、AWSのfluent-bitのトラブルシューティングがあったのでここを参考にしました。\n https://github.com/aws/aws-for-fluent-bit/blob/mainline/troubleshooting/debugging.md  Scalingの章に高スループットでfluent-bitを運用するための方法が紹介されており、そこに「DaemonSetモデルからSidecarモデルへ」と「ログファイルのTailからLog Streamingモデルへ」の変更が有効であることが記述されていました。\nすぐにこれを採用し、最初に紹介したアーキテクチャへと変貌を遂げました\n具体的な設定 #  これら理由を踏まえた上で設定は次のようになります。\nnginxの出力先の設定 #  ログは取り扱いしやすいように一度JSONで出力しています。 syslogは/tmp/sidecar-nginx/sys-log.sockに対して出力しています。\nlog_format json_access_format escape=json \u0026#39;{ 中略 }\u0026#39; server {  access_log syslog:server=unix:/tmp/sidecar-nginx/sys-log.sock json_access_format; } fluent-bit #  INPUTは/tmp/sidecar-nginx/sys-log.sockからnginxのログをJSON形式で読み込み、 syslog → JSON → 日付抽出 → タグの書き換え(出力先の調整)FILTERを通った後、 ファイルに書き出しています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  [SERVICE]  Flush 1  Grace 120  Daemon off  Parsers_File parsers.conf  HTTP_Server On  HTTP_Listen 0.0.0.0  HTTP_PORT 2020  Log_Level info  [INPUT]  Name syslog  Tag kube.*  Path /tmp/sidecar-nginx/sys-log.sock  Parser syslog-rfc3164-local  Mode unix_udp  [FILTER]  Name parser   Match kube.*  Key_Name message  Preserve_Key true  Reserve_Data true  Parser json  [FILTER]  Name lua  Match kube.*  script create-log-file-path.lua  call create_log_file_path  [FILTER]  Name rewrite_tag  Match kube.*  Rule vhost ^(.*)$ /log/output/path/$log_file_path true  [PARSER]  Name nginx_access_log  Format regex  Regex ^(?\u0026lt;container_log_time\u0026gt;[^ ]+) (?\u0026lt;stream\u0026gt;stdout|stderr) (?\u0026lt;logtag\u0026gt;[^ ]*) (?\u0026lt;message\u0026gt;.*)$  Time_Key time  Time_Format %Y-%m-%dT%H:%M:%S%z  Time_Keep On  [PARSER]  Name syslog-rfc3164-local  Format regex  Regex ^\u0026lt;(?\u0026lt;pri\u0026gt;[0-9]+)\u0026gt;(?\u0026lt;time\u0026gt;[^ ]* {1,2}[^ ]* [^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_/.-]*)(?:[(?\u0026lt;pid\u0026gt;[0-9]+)])?(?:[^:]*:)? *(?\u0026lt;message\u0026gt;.*)$  Time_Key time  Time_Format %b %d %H:%M:%S  Time_Keep On  [PARSER]  Name json  Format json  [OUTPUT]  Name file  Match *  Format template  Template method:{method}\turi:{uri} 中略   日付順で出力するために、以下のlua scriptを利用してTagを書き換えています。\n-- create-log-file-path.lua function create_log_file_path(tag, timestamp, record)  new_record = record  new_record[\u0026#34;log_file_path\u0026#34;] = os.date(\u0026#34;%Y-%m%d\u0026#34;,timestamp)..\u0026#34;/istio-ingressgateway-access.log\u0026#34;  return 1, timestamp, new_record end IstioOperator #  KubernetesのManifestファイルは次のようになります\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117  apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata:  name: istio-my-ingressgateway spec:  profile: empty  components:  ingressGateways:  - name: istio-my-ingressgateway  enabled: true  k8s:  overlays:  - apiVersion: apps/v1  kind: Deployment  name: istio-my-ingressgateway  patches:  - path: spec.template.spec.containers[1]  value:  name: sidecar-nginx  env:  - name: TZ  value: Asia/Tokyo  image: # nginx  securityContext:  privileged: true  runAsUser: 0  runAsGroup: 0  runAsNonRoot: false  volumeMounts:  - name: cache-volume  mountPath: /var/cache/nginx  - name: pid-volume  mountPath: /var/run  - name: ingressgateway-sidecar-nginx-conf  mountPath: /etc/nginx  readOnly: true  - name: nginx-unix-socket  mountPath: /tmp/sidecar-nginx # nginxのsyslog出力場所  - path: spec.template.spec.containers[2]  value:  name: sidecar-fluent-bit  image: fluent/fluent-bit:1.8.13  imagePullPolicy: Always  ports:  - containerPort: 2020  securityContext:  privileged: true  runAsUser: 0  runAsGroup: 0  runAsNonRoot: false  readinessProbe:  httpGet:  path: /api/v1/metrics/prometheus  port: 2020  failureThreshold: 3  timeoutSeconds: 3  livenessProbe:  httpGet:  path: /  port: 2020  failureThreshold: 3  timeoutSeconds: 3  resources:  requests:  cpu: 150m  memory: 128Mi  limits:  cpu: 150m  memory: 128Mi  volumeMounts:  - name: sidecar-fluent-bit  mountPath: /fluent-bit/etc  - name: log-output-volume  mountPath: /log/output/path # fluent-bitのログの出力場所  - name: nginx-unix-socket  # fluent-bitがfluent-bitのUNIX Socketを読み込む場所  mountPath: /tmp/sidecar-nginx  - path: spec.template.spec.volumes[8]  value:  name: ingressgateway-sidecar-nginx-conf  configMap:  name: ingressgateway-sidecar-nginx-conf  items:  - key: nginx.conf  path: nginx.conf  - path: spec.template.spec.volumes[9]  value:  name: sidecar-nginx-error-page  configMap:  name: sidecar-nginx-error-page  - path: spec.template.spec.volumes[10]  value:  name: cache-volume  emptyDir: {}  - path: spec.template.spec.volumes[11]  value:  name: pid-volume  emptyDir: {}  - path: spec.template.spec.volumes[12]  value:  name: varlog  hostPath:  path: /var/log  - path: spec.template.spec.volumes[13]  value:  name: sidecar-fluent-bit  configMap:  name: sidecar-fluent-bit  - path: spec.template.spec.volumes[14]  value:  name: log-output-volume  hostPath:  path: /log/output/path  - path: spec.template.spec.volumes[15]  value:  name: nginx-unix-socket  emptyDir: {}   /tmp/sidecar-nginxに対してUnix Socket用のEmpty Directoryを作成し、Pod内でシェアすることでPodとして見たときにポータビリティが確保できます。\nIstioOperatorで新しくContainerやVolumeを追加する場合は現状 k8s.overlays で頑張って追加するしかありませんが、 ManifestをTypeScriptで管理しているため、管理が難しいなどの問題は発生しませんでした。\nただしバージョンアップに伴ってIstioOperatorが作成するIngressGatewayのDeploymentを確認する必要があります。 早々バージョン更新の頻度は高くないので、バージョン更新後の検証と同時にやっても問題ないでしょう。\nこれから #  ここまでに説明したことを改めて整理すると、移行時に飲み込んだ冗長的な部分を最適化することがまずできます。\n nginxのログ出力をIngress Gatewayのistio-proxyで実施する fluentdによるログ転送処理をfluent-bitに移行する  これらを実施することでIstioOperatorのManifestはある程度見やすくなります。\n"},{"id":9,"href":"/docs/service-mesh/traffic-management/","title":"Istio Ingress Gatewayの設定","section":"Service Mesh (Istio)","content":"Istio Ingress Gatewayの設定 #  Ingress Gatewayクラスター外部に対してクラスター内部のServiceに対するルーティングを公開します(Ingressとは何か)。 IstioもIngress Gatewayを提供しており、L7のルーティング設定を記述することができます。\nIstio Ingress Gatewayの設定を変更するためにはいくつかのComponentを定義する必要があり、代表的なのはドキュメント(Istio / Ingress Gateways)で紹介されているGatewayとVirtualServiceになります。 nginxやApacheのようにconfファイルを起動時に読み込む形式と違い、istioがEnvoyに対してAPI経由で設定変更を動的に変更することになります。 そのため、どのistio-proxy(GatewayもしくはSidecarとして機能しているEnvoy)に対して設定を適用させるか記述する必要があります。\nここでは、以下の図中のIstio Ingress Gatewayに対して設定を変更します。\nhostsでルーティングを分ける #  例えばPCとスマートフォン(SP)でルーティング先を分けたい場合があります。 これを実現するためにはまずはGatewayを宣言する必要があります。 ここではわかりやすいようにPCのルーティング先をpc.example.com、SPの行き先をsp.example.comとして定義します。\nPC用Gateway\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata:  name: pc-example-com  namespace: demo spec:  selector:  app.kubernetes.io/name: istio-ingressgateway  app.kubernetes.io/part-of: istio  servers:  - port:  number: 33000  name: http  protocol: HTTP  hosts:  - pc.example.com   SP用Gateway\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata:  name: sp-example-com  namespace: demo spec:  selector:  app.kubernetes.io/name: istio-ingressgateway  app.kubernetes.io/part-of: istio  servers:  - port:  number: 33000  name: http  protocol: HTTP  hosts:  - sp.example.com   このとき、.metadata.namespaceと.spec.selectorで設定を適用したいIstio IngressGatewayを絞り込みます。 仮にGatewayを定義しなかった場合、Istio IngressGatewayはリクエストを後方のマイクロサービスに疎通させません。 次に、このGatewayをVirtualServiceに対してバインドします。\nPC版Virtual Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata:  name: pc-route  namespace: demo spec:  gateways:  - pc-example-com  hosts:  - \u0026#34;*\u0026#34;  http:  - name: http-route  match:  - uri:  prefix: /  route:  - destination:  host: pc.demo.svc.cluster.local  port:  number: 80  weight: 100   SP版Virtual Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata:  name: sp-route  namespace: demo spec:  gateways:  - sp-example-com  hosts:  - \u0026#34;*\u0026#34;  http:  - name: http-route  match:  - uri:  prefix: /  route:  - destination:  host: sp.demo.svc.cluster.local  port:  number: 80  weight: 100   Virtual Serviceは.spec.gateways[]にGatewayの.metadata.name(namespace内でユニーク)を指定することで、 同一namespace内のGatewayを特定してバインドしています。\n語弊を恐れずにこれらのコンポーネントの流れを書くと次のようになります。\n[host]pc.example.com:33000 # アクセス → [Gateway]pc-example-com # hostsとPortの宣言 → [VirtualService]pc-route # Gatewayのバインド、PATHに対するServiceへルーティング → [Service]pc.demo.svc.cluster.local # Podに対するルーティング 以上でhostsに対するルーティングを実現することができます。\nまた、これらの操作により、同じnamespace内でpcとspで別々のIngress Gatewayに分離したい要求が発生した場合はIngress Gatewayが増えた場合は Gatewayの.metadata.selectorを調整することで対応することができます。\nHeaderやQueryParameterでルーティングする #  Virtual ServiceはURIやHeader、Query Parameterなどの情報をもとに、ルーティング先のServiceを変更することができます。 Argo Rolloutsはこの機能を利用してBlueGreenデプロイや、Canaryデプロイを実現しています。 デプロイの機能として利用するだけでなく例えば「Preview版の機能を特定のHeader情報を含む場合にのみ公開する」などを実現することが可能です。\n例えば、Headerにversion: v2が含まれる場合は、.metadata.name=pc-v2のServiceにルーティングする設定は次のように書くことができます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata:  name: include-preview-route  namespace: demo spec:  gateways:  - pc-example-com  hosts:  - \u0026#34;*\u0026#34;  http:  - name: http-preview  match:  - uri:  prefix: /  headers: # queryParamsにすると ?preview=v2 でルーティングされる  preview:  version: v2  route:  - destination:  host: pc-v2.demo.svc.cluster.local  port:  number: 80  - name: http-common  match:  - uri:  prefix: /  route:  - destination:  host: pc.demo.svc.cluster.local  port:  number: 80   試験的に実現したい機能などを本番環境に投入したい場合などに役に立つことは間違いないでしょう。\nVirtualServiceを記述する注意点として、.spec.http[]は条件の厳しいものが先にくるように記述する必要があります。 また、ルーティング先のhostとなるServiceが存在しない場合はManifestがApplyできないことがあります。\n"},{"id":10,"href":"/docs/rate-limit/global-ratelimit/","title":"Global RateLimit","section":"Rate Limit","content":"Global RateLimit #  Global Rate LimitはIngress Gatewayより後方側にいるPodに対するリクエストの流量制限を実施します。 すなわち、Kubernetesクラスターまではリクエストは到達します。 envoyproxy/ratelimitはこれを実現するためのリファレンス実装で、外部サービスとして後付で導入することが可能です。\nTrafficがingress gatewayに到達した後の大雑把な流れは次のとおりです。\n rate_limit_serviceで指定されたマイクロサービスにたいしてgrpcで問い合わせをします。 envoyratelimitはredis（memcacheも利用可）に格納したDescriptorに対するリクエスト数の計算を実施します。  ratelimit.go#L164 fixed_cache_impl.go#L39-L128   結果をingress gatewayに対してRateLimitResponseに乗せて返却 ingress gatewayはレスポンスを受けて429を返すかどうか決定する。  Global Ratelimitの設定 #  envoyproxy/ratelimitを利用するには2つの設定が必要です。\n Descriptorの設置 Descriptorに対するRate Limitの定義  DescriptorはEnvoy（istio-proxy）に対して定義することが可能で、Gatewayとして機能しているistio-proxyだけでなく、Sidecarとして搭載されているistio-proxyに対しても定義することが可能です。\nDescriptorはActionによって条件が定義することができ、これをリファレンス実装されたratelimitのマイクロサービスで使用することにより、特定のPATHやheaderに対してratelimitを適用することができます。\n具体的な例を示しましょう。\n:path単位でRate Limitをかける #  例えば、/というパスに対してRate Limitを作りたい場合、まずDescriptorをGatewayのistio-proxyに対して作る必要があります。\napiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata:  name: ratelimit-actions spec:  workloadSelector:  labels:  app: istio-ingressgateway  configPatches:  - applyTo: VIRTUAL_HOST  match:  context: GATEWAY  routeConfiguration:  vhost:  name: \u0026#34;\u0026#34;  route:  action: ANY  patch:  operation: MERGE  value:  rate_limits:  - actions:  - request_headers:  # HTTPの場合Request Headerの`:path`にURIが格納されている  header_name: \u0026#34;:path\u0026#34;  # \u0026#34;PATH\u0026#34;という名前でDescriptorを作成する  descriptor_key: PATH ※ これ以降、rate_limitsより上層の定義は省略します。\nこのPATHに対してenvoyproyx/ratelimitによって10 rpm (request / minutes)の制限を加える定義は次のようになります。\ndescriptors:  - key: PATH # actionsに定義したdescriptor_key  value: /  # Descriptorが取得するValue、つまり今回の場合はURI  rate_limit:  unit: minute  requests_per_unit: 10 正規表現でDescriptorを絞り込む\n実践的にはより複雑なURIに対してRate Limitを書けることになるます。 ニコニコ生放送では/watch/lv12345...といった具合のURIに対して制限を適用する必要があります。\nこの場合Descriptorの定義は正規表現を以下のように記述することで表現することができます。\nrate_limits:  - actions:  - header_value_match:  descriptor_value: watch  headers:  - name: \u0026#34;:path\u0026#34;  safe_regex_match:  google_re2: {}  regex: /watch/(lv\\d+) Rate Limitは前回と同様にDescriptorに対して記述するだけで定義できます。\ndescriptors:  - key: header_match  value: watch  rate_limit:  unit: second  requests_per_unit: 9999999 istio-proxyとRate Limitのマイクロサービスとの連携 #  次のようなEnvoyFilterをIngress Gatewayに対して適用しています。\napiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata:  name: ratelimit-gateway spec:  workloadSelector:  labels:  app: istio-ingressgateway  configPatches:  - applyTo: HTTP_FILTER  match:  context: GATEWAY  listener:  filterChain:  filter:  name: envoy.filters.network.http_connection_manager  subFilter:  name: envoy.filters.http.router  patch:  operation: INSERT_BEFORE  value:  name: envoy.filters.http.ratelimit  typed_config:  \u0026#34;@type\u0026#34;: type.googleapis.com/envoy.extensions.filters.http.ratelimit.v3.RateLimit  domain: nicolive  # Envoy Ratelimitとの疎通が失敗した場合など、  # トラフィックをUpstreamに流れるようにする  failure_mode_deny: true  timeout: 10s  rate_limit_service:  grpc_service:  envoy_grpc:  # Istioのドキュメントとここが異なる  cluster_name: outbound|8081||ratelimit.mynamespace.svc.cluster.local  authority: ratelimit.mynamespace.svc.cluster.local  transport_api_version: V3 Istioのドキュメントをそのまま流用した場合、 EnvoyのCluster定義を追加する記述がありますが、これはKubernetesのServiceを以下のように定義するとEDS（Endpoint Discovery Service）によって 利用可能なcluster_name: outbound|8081||ratelimit.mynamespace.svc.cluster.localが自動的に定義されます。\nこれにより、cluster名をSTATIC_DNS（L4）からEDS（L7）に変更することができ、Rate LimitのPodの更新時に瞬断が発生しなくなります。\napiVersion: v1 kind: Service metadata:  name: ratelimit spec:  type: ClusterIP  selector:  app: ratelimit  app.kubernetes.io/name: ratelimit  ports:  - name: http-ratelimit-svc  port: 8080  targetPort: 8080  protocol: TCP  - name: grpc-ratelimit-svc  port: 8081  targetPort: 8081  protocol: TCP  - name: http-debug-ratelimit-svc  port: 6070  targetPort: 6070  protocol: TCP また、RateLimitとの疎通はfailure_mode_deny: falseを指定しています。 Ingress Gatewayに対するアクセスはすべてが一度Rate LimitのPodを経由します。 デフォルトの場合（failure_mode_deny: true）、何らかの理由でRate LimitのPodとの疎通が取れなくなった場合にIngress Gatewayからユーザーに対して503エラーが返るようになります。 この影響はサービス全体に波及するためこのフラグはfalseにしています。\n仮にGlobal RateLimitが機能しなくなった場合、リクエストはそのままUpstream側のマイクロサービスまで貫通しますが、 異常なリクエストに対しては次に紹介するLocal Ratelimitによって多重の防御が用意されています。\n"},{"id":11,"href":"/docs/rate-limit/local-ratelimit/","title":"Local RateLimit","section":"Rate Limit","content":"Local RateLimit #  Global RateLimitとの違い\nLocal RateLimitとGlobal RateLimitの違いは守るスコープの違いにあります。 Global RateLimitはUpstream側のシステムを守るため、RateLimitのマイクロサービス間でリクエスト数を共有するためのストア(redisなど)を外側に持っています。 それに対し、Local RateLimitはRateLimitを提供するProxyだけがリクエスト数を保持でいればよいためインメモリーで実装することができます。\nKubernetes上におけるLocal RateLimitの設置候補\nLocal RateLimitを実施する候補は2つあります。\n istio-proxy（Envoy）のLocal Ratelimit機能を利用する nginxをistio-proxyとAppの間に立たせ、nginxのRateLimitを利用する  envoy と nginx の Rate Limit アルゴリズムの違い #  envoy と nginx では Rate Limit のアルゴリズムが異なります。 ゆえに、バースト性のあるトラフィックに対する制限が異なり、どちらからの乗り換えに対しても検証なしで乗り換えすることはできません。\n   Proxy Server Rate Limit Algorithm     nginx Leaky Bucket   envoy Token Bucket    envoyとnginxの設定例 #  例えばmyappというアプリケーションに対して10 rpsの Rate Limit の制限をかけ、バースト時のリクエストは50 rpsまで受け付けるようにした場合次のように記述できます。\nEnvoyののLocal Rate Limit設定例 #  apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata:  name: filter-local-ratelimit-myapp spec:  workloadSelector:  labels:  app: myapp  configPatches:  - applyTo: HTTP_FILTER  match:  context: SIDECAR_INBOUND  listener:  filterChain:  filter:  name: envoy.filters.network.http_connection_manager  patch:  operation: INSERT_BEFORE  value:  stat_prefix: http_local_rate_limiter  # Local Ratelimitのパラメーター  token_bucket:  max_tokens: 50  tokens_per_fill: 10  fill_interval: 1s  filter_enabled:  runtime_key: local_rate_limit_enabled  default_value:  numerator: 100  denominator: HUNDRED  filter_enforced:  runtime_key: local_rate_limit_enforced  default_value:  numerator: 100  denominator: HUNDRED nginxのRate Limit設定例 #  http { limit_req_zone myapp_zone zone=myapp_zone:1m rate=10r/s; server { location /myapp { limit_req zone=myapp_zone burst=50 delay=10; limit_req_status 429; # 省略 ... } } } どちらを選ぶか #  これらを選択するにあたりバースト時の挙動を確認する必要があります。 例えば、前述の設定で 1 つの Pod に対して 70rps 来た場合、envoy と nginx は次の挙動をします。\n   proxy 挙動     envoy max_tokens: 50まで消費し、50rps が App まで到達する。fill_intervalが 10 で指定されているためそれ以降のリクエストは token が回復するまで10rpsを維持する。max_tokens: 50から溢れた 20rps は 429 を返す。   nginx burst=50で指定したリクエスト数まで一度 nginx で受け付け、delay=10で指定した 10 req 分だけ App まで到達する。残りの 40req はキューイングされて FIFO で処理される。burst=50から溢れた 20rps は 429 を返す。    つまり、envoy で Local RateLimit を敷いた場合はmax_tokensで指定したリクエストはたしかに受け付けますが、それをキューせずに Upstream の App にリクエストを流します。この流量をアプリケーション側が処理することが可能であればenvoyの Rate Limit を採用することができます。これが逆に処理できない場合は App のコンテナが処理しきれずに 503 を返します。\nしたがって、バースト耐性を獲得しつつ、移行というスケジュールが決まった範疇で選択できるのはnginxを利用した Local Rate Limit になります。istio-proxyに加えてnginxもproxyとして挟まりスループットが若干悪くなりますが、BFFを構成するサーバーの応答速度と比較して十分に小さいため許容することにしました。\n今後どうするか #  Podを構成する要素としてProxyが2段構えになっているのは多少格好は悪いですが、うまく機能しています。 ただし、後述しますが、envoyやnginxのRateLimitでは負荷の上昇を防げないパターン問題点もあります。 アクセス傾向やPodのMetricsなどを総合的に鑑みてRate Limitの構成と設定値を決めていく必要があります。\n"},{"id":12,"href":"/docs/rate-limit/ratelimit-is-unless/","title":"RateLimitで負荷の上昇を防げないパターン","section":"Rate Limit","content":"RateLimitで負荷の上昇を防げないパターン #  RateLimit を導入したからといって必ずしも負荷状態をバーストさせない状態を作れるわけではありません。 Global RateLimit として利用可能なenvoyproxy/ratelimitや、 Envoy 本体にある Local RateLimit、nginx の持つ RateLimit の実装を注意深く見ると、RateLimit の計算に利用するのはリクエストのみです。 すなわち、レスポンスが返ったことを確認してカウントアップしたリクエスト数を下げるわけではないのです。 これはつまり、RateLimit よりも後方のサーバーがコネクションをキューイングした場合、RateLimit で指定したリクエスト数より多くのリクエストを処理することが可能になります。\n発生メカニズム #  簡略化したシーケンス図でまずは状況を説明します。図中には以下が登場します。\n   名称 役割     User ブラウザなどのクライアント   Proxy Request に対する Rate Limit を適用   Server(Frontend) BFF Server と置き換えても問題ない。図中のHeavy TaskはServer Side Renderingと解釈するとよい。   Server(Backend) Server(Frontend)が少なくとも1つ以上はクリティカルに依存するサーバー    RateLimitが効いているにも関わらずServer(Frontend)のCPU使用率が上昇する流れ\n 何らかの理由によってServer(Backend)のレスポンスが遅くなる場合が発生 このとき、Server(Frontend)からのリクエストは設定したtimeoutまでコネクションを維持し続ける RateLimitはRequestに対してのみ有効なため、Limitが効かない間はServer(Frontend)にリクエストを送信する Server(Backend)のレスポンスタイムが正常に戻ると図中の4のResponseが発生する すると、Server(Frontend)にキューイングされたリクエストHeavy Taskが定常よりも多く実行される その結果、Server(Frontend)のCPU使用率が上昇する  問題点と対策 #  基本的にどのマイクロサービスも、連携しているマイクロサービスにSLA(Service Level Agreements)を満たせない可能性がある前提で振る舞いを決める必要があります。\n問題点\n今回のケースだと、Server(Backend)のレスポンスが伸びた場合、Server(Frontend)がリクエストをキューイングするところに問題点があります。 Server(Frontend)がレスポンスを返すために必要な情報を集めるために長めにタイムアウトを取っている場合、障害時にこのタイムアウト分だけコネクションが維持されることを忘れてはいけません。\n対策\nアプリケーションレベルの対応だと適切なタイムアウト設定や、そもそも高負荷になりうる処理がバーストしないように処理を組み替えるなどの対応が必要になってきます。 とはいえ、そこまで工数をかけられない場合はコネクション数を絞ったり、istio(envoy)のサーキットブレーカーなどの機能を有効にして、問題が波及しないように布石を打つ必要があります。\n Circuit breakers — envoy documentation Istio / Circuit Breaking  "},{"id":13,"href":"/docs/scalability/horizontal-pod-autoscaler/","title":"水平スケール","section":"スケーリング","content":"水平スケール #  Kubernetesは監視しているCPU使用率などのMetricsをもとにPodの数を自動的にスケーリングさせる機構、Horizontal Pod Autoscalingを持っています。 metrics serverを利用するとCPU使用率やMemory使用量をベースに水平スケールを支援してくれます。\nHorizontal Pod Autoscaler #  Horizontal Pod Autoscaler（以下HPA）は観測されたMetricsを元に指定のPodのreplicasを増減させる仕組みです。 Manifestの書き方はシンプルで、autoscaling/v2beta2で記述すると次のようになります。\napiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata:  name: myapp spec:  minReplicas: 10  maxReplicas: 20  scaleTargetRef:  kind: Deployment # Argo Rolloutsを使用している場合は Rollout を指定する  apiVersion: argoproj.io/v1alpha1  name: myapp  metrics:  - type: Resource  resource:  name: cpu  target:  type: Utilization  averageUtilization: 80 これは探索されたPodのCPU使用率が80%を超えるようになった場合に、それを下回るようにPod数を増加させます。 逆に下回った場合はminReplicasまで戻るように働きます。\n注意点として、\n  \\[\\text{CPU使用率/1Pod} = \\frac{\\text{Podを構成するコンテナ全体の使用中のコア数の合計}}{\\text{各コンテナのlimits.cpuの合計}}\\]  で算出されます。つまり、Sidecarとして挿入されるistio-proxyのResourceも考慮した上でHPAの閾値を考慮する必要があります。実際に使用されているResourceは以下のCLIコマンドで確認できます。\nkubectl top pod myapp-[podid] kubectl top pod --containers myapp-[podid]  Support for resource metrics  これらを踏まえた上でHPAの設計をします。\nリソースの値をどうやって決めるか #  BFFを含むPodの大きな特徴として、\n Stateless 他マイクロサービスからデータを収集する Server Side Renderingを実施することもある  という点が上げられます。つまり、リクエストがBFFに滞在する時間が長くなることを基本的には想定はしていません。 このことから単純にRequest Per Sec(RPS)に比例してCPU使用率が上昇することが予測できるため次のような比例グラフが書けます。\nただし、Podの性能限界が存在するため無尽蔵に1つのPodのRPSが伸びるわけではありません。 途中で比例グラフが破綻するか、正常レスポンスを返せなくなるところがあります。 図中のPod Performance Limitはこれを示しています。\nまた、(Global / Local) Rate Limitで流量制御はPodがPod Performance Limitのrpsよりも低く、 HPAが発動するRPSよりも大きく指定する必要があります。\nこれらの値を決定するためには負荷試験を実施することで値を予測することが可能になります。\nバースト性のあるリクエストをどうやって耐えるか #  予測可能なバーストリクエスト数は事前にスケールアウトしておくことで必要なスループットを確保することができます。 ニコニコ生放送のように人気番組が発生するようなケースはHPA External Metricsを利用して動的にスケールアウトをスケジューリングする方法が考えられます（参考文献1, 2）。\nしかしながら、実際には予測不能な負荷はどうするか考える必要があります。 結論から言えばPod数を単純に多くして、定常時のResourceのCPU Requestをその分小さくします（下限はあります）。 そして、サービスが担保する最大rpsをGlobal Rate Limitによって制限することでそれを超えるリクエストはステータスコード429を返すようにします。\nつまり次のような計算式でrpsを最大にするためのreplicasとresources.requests.cpuを算出できます。\n \\[\\text{replicas} \\times \\text{containers[].resources.requests.cpu} = \\text{全体のrequests.cpu}\\]   \\[\\text{replicas} \\times \\text{HPA Trigger rps} = \\text{スケールアウトしない場合の全体のrps}\\]   \\[\\text{スケールアウトしない最大のrps} = \\frac{\\text{全体のrequests.cpu (最大値)}}{\\text{containers[].resources.requests.cpu (最小値)}} \\times \\text{HPA Trigger rps}\\]   注意\n containers[].resources.requests.cpuは下げすぎるとPodが起動しないことがあるため、下限があります。 全体のrequests.cpuはクラスターのリソース内でしか割り当てられないため、上限があります。   これでスケールアウトせずに処理可能なrpsの最大値を得ることができます。\nまた、Global RateLimitの値は次のどちらか小さい方の値を採用します。\n BFFがスケールアウトせずに処理できるrps（前述） BFFより後方のマイクロサービスが処理可能なrpsの最大値  これを超えるような場合は増資増強が必要になってきます。\n水平スケール設計の今後 #  バースト耐性を持たせるためには大量のPodを常時配置しておく必要がありますが、やはりそれでは余剰リソースが出てしまうので、Kubernetes HPA External Metricsを利用したスケールアウトの柔軟なスケジューリングの構成も必要になってきます。 ただし、リソースはやはり有限であるため優先度の高いPodからスケールアウトするようにPod Priority and Preemptionも決めていく必要があります。これらの精度を上げていくには、Podを構成する個々のアプリケーションのパフォーマンスについてより詳しくなる必要があり、洗練された負荷試験が必要なことがわかります。\n参考文献 #   Kubernetes HPA External Metrics を利用した Scheduled-Scaling - スタディサプリ Product Team Blog Kubernetes HPA External Metrics の事例紹介 | メルカリエンジニアリング  "},{"id":14,"href":"/docs/performance/load-test/","title":"負荷試験","section":"負荷","content":"負荷試験 #  負荷試験の目的 #  Docker SwarmからKubernetesに移行するにあたり、移行前のスペックを移行後に同等以上のスペックを発揮することを試験する必要があります。 したがって、アプリケーション自体の詳細な性能テストではなく、クラスターとして同等の性能が発揮できていることが大雑把でも確認できればよい、というのがここでのゴールとなります。\n評価するためにはPrometheusやDataDog Agentなどから収集したデータをGrafanaやDataDog Dashboardで確認しつつ再現性を持った試験を実施する必要があります。\n何を試験するか #  実際に試験して確認した内容を次の表にまとめました。\n   試験内容 目的     経路上の Proxy を最小台数にしたときに想定するrpsを処理ことができるか確かめる Connection Pool や TCP ESTABLISHED に余裕があるか確認する   Runtime（nodejs）やライブラリの処理可能なrpsを計測する 同じ Runtime やライブラリを使用しているアプリケーションの CPU/MEM リソースの基準値を見積もる   Pod をスケールアウトしたときの rps に対するリソースの変化を確認する Pod 数に対するリソース使用量と rps の関係を把握する   連続的にリクエストを投げることでほかサービスに影響がないか確認する 負荷試験の対象は挙動に問題ないが、同じ Gateway を使っている場合や同じマシンに乗っている他のサービスに影響がないことを確かめる    基本的に「性能限界」と「リソースの見積」のための試験になります。 これらの情報を元に、常設のreplicasの見積りや、Horizontal Pod AutoscalerのためのCPUのlimit設定、 共倒れを防ぐためのRate Limit設定を割り出していきます。\n合わせてリソースの値をどうやって決めるかを確認してみてください。\n試験方法 #  他のマイクロサービスと連携していないHTTPサーバーを用意する #  Kubernetesの一連の動作検証も含め以下のようなサーバーを用意しておくと検証が捗ります。\nimport * as express from \u0026#34;express\u0026#34;;  const app = express();  app.get(\u0026#34;/\u0026#34;, (req: express.Request, res: express.Response) =\u0026gt; {  res.send(\u0026#34;ok\u0026#34;); });  const httpServer = server.listen(3000, \u0026#34;0.0.0.0\u0026#34;);  process.on(\u0026#34;SIGTERM\u0026#34;, () =\u0026gt; {  httpServer.close(); }); このサーバーをコンテナ化してKubernetes上で稼働させ、疎通確認や負荷試験の対象として扱います。\n負荷試験ツール #  使用したツールで簡易で便利だったのがtsenart/vegetaでした。 Binaryで手に入るためセットアップが容易で適当なサーバーから直接実行したり、docker-composeでローカルに環境を作り、その中で動作確認ができるのは非常に作業効率が高いです。\n例えば1rpsのテストを実施したい場合は次のようなShellを実行するだけで済みます。\necho \u0026#34;GET http://test-server:3000\u0026#34; | vegeta attack -rate 1/1s \u0026gt; /dev/null これをistio-proxyから収集されたMetricsをGrafanaで可視化することで、まずは集計クエリが正しいことを確認していきます。 ある程度高いrpsで負荷をかけ続けると、パラメーターで指定したrpsよりも低い値で可視化されることがありますが、 負荷試験用のクライアントの性能だったり、常に均質なネットワークを提供できるわけではなかったりするためです。\nとはいえ負荷試験時のrps目標値があるため、観測されるrpsが目標値になるまでクライアント側のrpsを上げるか、 クライアントを分散して負荷を高めるなど工夫をします。\nProxyからリクエストをMirroringする #  いきなり移行対象のクラスターやサーバーに対してトラフィックを100%向けるのはかなり危険です。 見積もりが正しくともそれが確実かどうかはやってみなければわかりません。 安全に取るなら同じ流量のリクエストを移行後の機材に向けて検証した後に徐々にTraffic Weightを調整していくのが無難でしょう。\n一番手っ取り早いのはリクエストをミラーリングして実際のリクエストを受け付けることです。 BFFのサーバーの場合、リクエストのほとんどがGETであるためアクセスログを出力するロードバランサーより後方でミラーリングを実施することが可能です。\n実際に使用したミラーリングはnginxの機能によるものを利用しています。\n http://nginx.org/en/docs/http/ngx_http_mirror_module.html  実際には次のような経路でミラーリングを実施しました。\n移行後のクラスターに対してGETリクエストをミラーリングし、CPU/MEMなどのリソース使用量、エラー率をモニタリングツールで監視しました。 この結果と単純な負荷試験による見積もりの誤差を把握した上で移行に備えました。\n"},{"id":15,"href":"/docs/performance/monitoring/","title":"モニタリング","section":"負荷","content":"モニタリング #  言わずもがな、サーバーを持ちサービスを運用する上でモニタリングは必須です。 収集したログや Metrics は不正アクセスや障害の検知、アラートの発報などサービスの運営をする上で必ず必要な情報です。\n利用しているモニタリングツール #  今回利用しているモニタリングツールは以下の 2 つがあります。\n    Explorer DashBoard     1 Prometheus Grafana   2 DataDog Agent DataDog    2 つ存在する理由は、費用的な面とツールの精度を確認するための理由があります。\n DataDog は本番環境で使う。一部の開発環境でも検証可能な状態で利用する。 上記の DataDog を使わない環境では Prometheus と Grafana で代用する 2つのツールでモニタリングの精度を比較する（本来は最低でも 3 つあったほうが良い）  どちらも同じ Metrics を収集できるため単体での Observability の差に大きく違いはありません。 ただ DataLakeとしてDataDogがすでに基盤として存在しているためメインは DataDog に各種情報が集約されています。\nBFF サーバーの何を観測するか #  BFF サーバーにおいて観測する主要なものは以下の表にまとめました。 どれも時系列データとして記録されるため時間変化が分かる状態になっています\nBFF サーバーとして主に観測しているのは次のようなメトリクスになります。\n※ 略語\n rps = Request Per Seconds (1秒間あたりのリクエスト数)     メトリクス 目的     CPU 使用量の最大値、平均値、合計値 想定値との比較   Memory 使用量の最大値、平均値、合計値 メモリリークの観測、想定値との比較   HTTP Status Codeの数 200, 300, 400, 500 系の観測   リクエスト総数に対するStatus Code 500 の数 エラー率の観測   マイクロサービス間のResponse Time（HTTP, GRPC) ボトルネックの観測   マイクロサービス間のrps 実効rpsが想定内か観測する   Node ごとの replicas スケールアウトやデプロイの変化を観測する    BFF以外はアクセスログを出力するfluent-bitや、RateLimitを実施しているマイクロサービスも監視する対象となります。\nDataDogの例 #  具体的な例を紹介します。 DataDog のKubernetes タグ抽出では粒度の低いタグとして、 Kubernetes のRecommend Labelsが利用できます。\n   DataDog のタグ Kubernetes の Pod Label     kube_app_name app.kubernetes.io/name   kube_app_instance app.kubernetes.io/instance   kube_app_version app.kubernetes.io/version   kube_app_component app.kubernetes.io/component   kube_app_part_of app.kubernetes.io/part-of   kube_app_managed_by app.kubernetes.io/managed-by    TypeScriptでKubernetesのmanifestを記述するで紹介したように、これらのラベルを機械的に付与していくとDataDog上での分解能が飛躍的に向上します。 最も利用頻度の高いタグはkube_app_nameとkube_app_versionで、これらの2つは非常に重要な役割を担います。\n例えば、新しいPodをデプロイした際に、kube_app_versionをフィルタリングのクエリとして利用することで、 どの時刻で新旧のバージョンが入れ替わったのかが可視化されます。\nDashBoardでは他の指標と見比べる事が可能ですので、例えば新しいバージョンにバグが有り、マイクロサービス間の通信のエラー率が高まった場合の観測が可能です。\n上記のクエリは次のようになっています。\nTemplate Parameter\n $kube_app_name $kube_namespace  # Total CPU Usage autosmooth(sum:kubernetes.cpu.usage.total{$kube_app_name,$kube_namespace} by {kube_app_version}) # Total autosmooth(sum:kubernetes.memory.usage{$kube_app_name,$kube_namespace} by {kube_app_version})  # Error Resp Rate[%] a / b * 100 ## a  sum:istio.mesh.request.count.total{response_code:5*,$kube_app_name,$kube_namespace} by {response_code,destination_service,request_protocol,kube_app_version}.as_count() ## b  sum:istio.mesh.request.count.total{$kube_app_name,$kube_namespace} by {destination_service,request_protocol}.as_count() より高度な演算が可能なため、Error Resp Rate[%]のように複数のMetricsを組み合わせることが可能です。\nモニタリングの次にやること #  更新のたびにDashboardを見に行き、バグがないか確認するはいわゆる「トイル」な仕事になります。 Argo RolloutsではProgressive Deliveryを支援するためのAnalysis機能があり、 PrometheusやDataDogなどの集計データをもとにデプロイを続行するかどうか自動的に判断する事が可能です。\n https://argoproj.github.io/argo-rollouts/analysis/datadog/  これを導入するためにはまずは信頼できる指標の作成が必要で、 BFFサーバーは何を指標とするかはこれから吟味が必要です。\n"},{"id":16,"href":"/docs/performance/load-balancing/","title":"負荷分散","section":"負荷","content":"負荷対策 #  nodeSelector #  NodeはPodが配置されるVMや物理マシンですが、 配置されるPodの処理内容によって使用されるリソースが大きく変わることがあります。 具体的にはIngress Gatewayはクラスター内外のトラフィックを集中的に処理することが事前にわかっています。 また、Ingress Gatewayがなければアプリケーションにアクセスできないため、必ずリソースが枯渇しない状態にする必要があります。 そのため、Gatewayとしての役割以外を持つPodと別のNodeに配置されるようにすることで、Podが安定して稼働できるリソースの確保を実現します。\nKubernetesはNodeに対してラベルを付与し、PodにnodeSelectorを付与することで指定のNodeに対してPodを配置することができます。 Nodeに付与されているlabelは以下のコマンドで確認することができます。\n$ kubectl get nodes --show-labels # 簡単のため表示を省略 gateway01 Ready \u0026lt;none\u0026gt; 1d v1.21.12 node-role=gateway gateway02 Ready \u0026lt;none\u0026gt; 1d v1.21.12 node-role=gateway worker01 Ready \u0026lt;none\u0026gt; 1d v1.21.12 node-role=worker worker02 Ready \u0026lt;none\u0026gt; 1d v1.21.12 node-role=worker この場合、workerに対してPodを配置したい場合は次のように記述することができます。\n1 2 3 4 5 6 7 8 9 10 11  apiVersion: apps/v1 kind: Deployment metadata:  name: app  namespace: demo spec:  template:  # 中略  spec:  nodeSelector:  node-role: worker    Node上へのPodのスケジューリング | Kubernetes  PodAntiAffinity #  Podのスケジューリングはデフォルトのまま使用すると、Nodeに対する配置は明示的にコントロールされません。 つまり、あるアプリケーションを搭載したPodがNodeに偏らないようにしたいが、偏ってしまう（逆も然り）など発生します。 特にBFFサーバーはステートレスなサーバーであるため、分散配置されている方が望ましいでしょう。\nKubernetesではpodAffinity(podを条件に応じて集約)またはpodAntiAffinity(podを条件に応じて分散)を指定することでPodのスケジューリングをコントロールすることができます。 例えば、「app.kubernetes.io/name=myappというラベルを持つPodが、なるべく同じNodeに配置されない」スケジューリング設定は次のように表現できます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  apiVersion: apps/v1 kind: Deployment metadata:  name: myapp  namespace: demo  labels:  app: myapp  app.kubernetes.io/name: myapp spec:  template:  spec:  affinity:  # ポッド間のスケジューリングルール  # 以下の条件に合致する場所に配置しないポリシー  podAntiAffinity: # 逆は podAntiAffinity  # 優先的に考慮されるスケジューリングポリシー  preferredDuringSchedulingIgnoredDuringExecution:  - # 優先度の重み付け（1 - 100の間で定義）  # Nodeごとにweightを加算しScoreを算出し、  # 最も高いスコアを獲得したNodeに対してPodが配置される  weight: 1  # app.kubernetes.io/name = \u0026#34;myapp\u0026#34; のラベルを持つPod  podAffinityTerm:  # Nodeをフィルタリングするためのキー。  # この空間内のNodeに対するPod間のSelectorでAffinityのScoreが計算される  # kubernetes.io/hostnameは各Nodeに付与される識別子として利用できる  # (Nodeのフィルタリング条件として偏りがないキー)  topologyKey: kubernetes.io/hostname  labelSelector:  # app.kubernetes.io/name = \u0026#34;myapp\u0026#34; にマッチするPodを集計対象とする  matchExpressions:  - key: app.kubernetes.io/name  operator: In  values:  - myapp   preferredDuringSchedulingIgnoredDuringExecutionはpodAffinityTermで指定されたlabelSelectorに該当するPodをtopologyKeyごとにweightを加算してスコアを算出します。 podAntiAffinityで利用されるスコアになるため、スコアが高くなるほどPodはスコアの高いNodeに対してなるべく配置されないようになります。 （podAntiAffinityはスコアの符号がマイナスで、podAffinityはスコアの符号がプラスと思えばわかりやすい。）\nまた、ここではlabelSelectorで使うkeyやtopologyKeyはWell-Known Labelsを利用しています。\n Node上へのPodのスケジューリング | Kubernetes Well-Known Labels, Annotations and Taints | Kubernetes  "},{"id":17,"href":"/docs/migrate-practice/migrate-docker-swarm-to-kubernetes/","title":"移行の実施","section":"Docker SwarmからKubernetesへの移行","content":"移行の実施 #  移行前の状態（Phase 1）から移行後の状態（Phase 2）までのステップは次のような経路で実施しました。\n   Phase 経路     Phase 1 Apache → nginx → Container   Phase 2 Apache → istio-ingressgateway → App(Docker Swarm)   Phase 3 Apache → istio-ingressgateway → App(Kubernetes)    Apache による経路変更はパス単位（URI 単位）で実施できるため、流量が明らかに少ないパスを管理するマイクロサービスから移行を実施しました。\n移行の流れ #  移行時の細かい手順は次のようになります。\n ApacheのBalancerMemberを利用してからPhase 1からPhase 2に切り替え istio-ingressgatewayとKubernetes内のネットワーク系の状態を確認  負荷試験の結果と照らし合わせて Gatewayのリソース使用量などを見る   Phase 3への切り替え前に、Virtual Serviceで特定のHeaderかQuery Parameterを利用して移行後のPodに対してアクセス。 Kubernetes内への疎通も確認できた後、istio-ingressgatewayのTraffic Weightを完全に切り替える  rps がそこまで高くない BFF はこの手順を繰り返すことで移行を淡々とすすめることができました。 高 rps の BFF サーバーはこの手順でやるにはリスクが高いので、トラフィックのミラーリングを実施して Gateway と Kubernetes クラスター全体の状態を確認していきます。 アクセスログで紹介したようにPodにログ出力のためのnginxが含まれるため、二重計上されないためにNodePortをistio-proxyに向けたものをミラーリングのためのポートとして提供しています。 nginxのミラーリングによって高rpsの時間変化がDataDogに蓄積され、そこから対応表を用いてリソースの逆算を実施し、移行フェーズへステップを進めることができました。\n\nロールバック設計 #  Phase 1, 2, 3 で移行ステップが区切られているのはロールバックのためです。 Istio の Virtual ServiceやGatewayに指定するパラメーターはAllow List形式であるため、明示的に指定しなければ疎通が取れません（全部通す設定も可能ではある）。 ゆえにアプリケーション側で必要なURIが開放されていない場合などにエラーが発生するため、ロールバックする可能性が十分にありました。 即時性を考えた結果、Phase1と2の状態を用意することで影響範囲に応じて即ロールバックできる状態にすることで落ち着きました。\n結果は何度か Phase 1、2の状態に戻すことはありました。ただ、これによって得られたものは、 Manifestにアプリケーションのルーティングの仕様が明示的に記述されるようになり、忘却されにくい状態になりました。\nスケジュールの振り返り #     時期 内容     2021/07 Kubernetesの移行作業着手   2021/12 Production環境でのKubernetes移行実施   2022/03 Production環境での移行作業完了    この間、Kubernetes 自体や Argo 系のアプリケーションの更新も実施ししています。\n   リリース時期 リリースされたもの     2021/04/09 Kubernetes v1.21.0   2021/08/05 Kubernetes v1.22.0   2021/08/20 Argo CD v2.1.0   2021/10/13 Argo Rollouts v1.1.0   2021/12/08 Kubernetes v1.23.0   2021/12/15 Argo CD v2.2.0   2022/03/06 Argo CD v2.3.0   2022/03/22 Argo Rollouts v1.2.0    ※ minor バージョンは省略\n移行中・移行後の運用 #  移行期間中、ArgoCDのGitOpsに則り、Manifestを管理するPull Requestを担当者が出す方式を取っていました。 しかしながら、高頻度で更新されるアプリケーションはこれが手間であるため、Slackからリリースに必要な準備一式が整うように調整しました。\nDocker Swarmからのデプロイ手順はSlack上でコマンドを打つことで準備ができるようになり、 Kubernetesどころかリポジトリそのものを意識することが減りました。より詳細はSlack Botによる自動化に書いています。\nまとめ #  仕事は段取り八分とよくいったもので、移行に要した時間のほとんどが検証作業に費やされています。 Kubernetesに加え、サービスメッシュの導入によってObservabilityが向上し、リアルタイムで多くの情報が得られました。 移行期間中もリソース消費の予測がかなり簡単にでき、定量的に決定できたことは今後もデプロイを確実かつスムーズにするのに大いに役に立つと考えられます。\n"},{"id":18,"href":"/docs/migrate-practice/application/","title":"アプリケーションの移行","section":"Docker SwarmからKubernetesへの移行","content":"アプリケーションの移行 #  Kubernetes移行にあたりBFFサーバーで調整した内容を紹介します。\nGraceful Shutdown #  プロセス終了命令(SIGTERM)などのシグナルを受け取ったときに、サーバーに残っているリクエストがレスポンスを返し終わってからプロセスを終了する仕組みです。 これはKubernetesでなくても実装すべき内容で、安全に処理を終わらせるために必要です。\nexpressでの実装例は次のとおりです。\nimport * as express from \u0026#34;express\u0026#34;;  const app = express();  const httpServer = app.listen(process.env.PORT || 80);  // SIGNALを受け取る process.on(\u0026#34;SIGTERM\u0026#34;, () =\u0026gt; {  httpServer.close(); }); process.onでSIGNALを受け取ることができるため、そこでHTTP ServerをCloseするだけになります。 他にもWebSocket Serverを起動している場合もここでclose処理を実施すると安全に終了できます。\n静的リソースのアップロード #  静的リソースはAmazon S3にアップロードされたファイルをCDN(CloudFront)から配信する形式を取っています。 そのため、S3にアップロードする処理が必要で、移行前はJenkinsでこれを実行していました。\n静的リソースはこれまでJenkinsのタスクによってアップロードしていましたが、KubernetesのJobとして移行しました。\n具体的には、アプリケーションのCIによってリリース用のnpmパッケージが作成され、Private Registryにアップロードされたり、 ものによってはGitHubのRelease Assetsにアップロードされたりしています。\nKubernetes上のJobは\n npm packageにリリースする静的リソースをダウンロードし、 静的リソースのホスティングに本当に必要なファイルだけを抽出し、 S3にアップロード  という処理を実施しています。\n内部の処理は環境変数で処理できるように実装されており、npmパッケージとアップロード先のS3の保存先を選ぶことができます。 また、Argo CDのSync Waveと組み合わせて、 アプリケーションのDeploymentがApplyされるより前にこのJobを実行するように順序を決めることでクリティカルパスを形成することができます。 以下は静的リソースのアップロードJobの例です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  apiVersion: batch/v1 kind: Job metadata:  name: static-resource-upload-job-v1.0.0  labels: \tapp: static-resource-upload-job-v1.0.0 \tversion: 1.0.0 \tapp.kubernetes.io/name: static-resource-upload-job \tapp.kubernetes.io/version: 1.0.0  annotations:  argocd.argoproj.io/sync-wave: \u0026#34;-1\u0026#34; spec:  ttlSecondsAfterFinished: 86400 # 24時間後にJobのPodが消える  template:  metadata:  labels:  app: static-resource-upload-job-v1.0.0  version: 1.0.0  app.kubernetes.io/name: static-resource-upload-job  app.kubernetes.io/version: 1.0.0  annotations:  sidecar.istio.io/inject: \u0026#34;false\u0026#34;  spec:  containers:  - name: static-resource-upload-job  env:  - name: S3_REGION  value: \u0026#34;upload-region\u0026#34;  - name: S3_BUCKET  value: \u0026#34;upload-bucket-name\u0026#34;  - name: NPM_PACKAGE_NAME  value: \u0026#34;npm package name\u0026#34;  - name: NPM_PACKAGE_VERSION  value: \u0026#34;version\u0026#34;  - name: NPM_PACKAGE_DIST_DIR  value: dist  - name: UPLOAD_DIST_DIR  value: \u0026#34;upload-dist-dir\u0026#34; # S3のKeyに該当  image: # 静的リソースをアップロードするための処理が実装されたDocker Image  restartPolicy: Never   "}]